{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9861e009-a76a-4d15-9544-7043f5280a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install  tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4d06a4-2495-4c90-a78a-cd7fe31a41e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\acer\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73b3b69-8a52-4a3e-9d30-50ea44c5e0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c63efcc-cb79-4cec-b257-32e61b78a109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.10.9)\n",
      "Requirement already satisfied: absl-py in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acer\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install  mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f6526e-4891-4c2a-a7b7-fba87543be09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "888e4c54-c093-41be-9a97-428e6e054fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.layers import (LSTM, Dense, Concatenate, Attention, Dropout, Softmax,\n",
    "                                     Input, Flatten, Activation, Bidirectional, Permute, multiply, \n",
    "                                     ConvLSTM2D, MaxPooling3D, TimeDistributed, Conv2D, MaxPooling2D)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# disable some of the tf/keras training warnings \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "# suppress untraced functions warning\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa6175f-be08-4403-a20c-416bab140899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-trained pose estimation model from Google Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Supported Mediapipe visualization tools\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315e1e36-1d70-44ba-adc1-7852409350aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"\n",
    "    This function detects human pose estimation keypoints from webcam footage\n",
    "    \n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37a000f-2506-4fcc-91fe-ab2445e23d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    \"\"\"\n",
    "    This function draws keypoints and landmarks detected by the human pose estimation model\n",
    "    \n",
    "    \"\"\"\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d117d63c-ce5e-4c13-afed-57212572ad40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # camera object\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # webcam video frame height\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # webcam video frame width\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # webcam video fram rate \n",
    "\n",
    "# Set and test mediapipe model using webcam\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "      \n",
    "        # Make detection\n",
    "        image, results = mediapipe_detection(frame, pose)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render detections\n",
    "        draw_landmarks(image, results)               \n",
    "        \n",
    "        # Display frame on screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Exit / break out logic\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486ca325-b4ad-4d66-9b06-0ac5478c0d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recollect and organize keypoints from the test\n",
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcaca19f-da38-4f92-86b5-93d4cdfdbf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 33 landmarks with 4 values (x, y, z, visibility)\n",
    "num_landmarks = len(landmarks)\n",
    "num_values = len(test)\n",
    "num_input_values = num_landmarks*num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687753d2-e944-4d1a-bf32-ee7e7c5fa38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an example of what we would use as an input into our AI models\n",
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b913d8df-51a8-4ebf-a97e-b5fa1133864a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \"\"\"\n",
    "    Processes and organizes the keypoints detected from the pose estimation model \n",
    "    to be used as inputs for the exercise decoder models\n",
    "    \n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716a5fa0-11fc-45ed-8f4f-fbe59b36814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\tensor\\project\\data\n"
     ]
    }
   ],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join(os. getcwd(),'data') \n",
    "print(DATA_PATH)\n",
    "\n",
    "# make directory if it does not exist yet\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# Actions/exercises that we try to detect\n",
    "actions = np.array(['curl', 'press', 'squat', 'pushup', 'leg_raise', 'jumping_jacks'])\n",
    "num_classes = len(actions)\n",
    "\n",
    "# How many videos worth of data\n",
    "no_sequences = 50\n",
    "\n",
    "# Videos are going to be this many frames in length\n",
    "sequence_length = FPS*1\n",
    "\n",
    "# Folder start\n",
    "# Change this to collect more data and not lose previously collected data\n",
    "start_folder = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "193e0577-83d3-4634-b40e-f7a66c735cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build folder paths\n",
    "for action in actions:     \n",
    "    for sequence in range(start_folder,no_sequences+start_folder):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))  \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b5c22e-4562-4ab9-921a-9871e0e7c838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colors associated with each exercise (e.g., curls are denoted by blue, squats are denoted by orange, etc.)\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245), (117,16,245), (245,16,117), (16,245,117)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0597ada9-155a-4f4a-bb51-4d53d417ef0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect Training Data\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    # Loop through actions\n",
    "    for idx, action in enumerate(actions):\n",
    "        # Loop through sequences (i.e., videos)\n",
    "        for sequence in range(start_folder, start_folder+no_sequences):\n",
    "            # Loop through video length (i.e, sequence length)\n",
    "            for frame_num in range(sequence_length):\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                # Make detection\n",
    "                image, results = mediapipe_detection(frame, pose)\n",
    "\n",
    "                # Extract landmarks\n",
    "                try:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Render detections\n",
    "                draw_landmarks(image, results) \n",
    "\n",
    "                # Apply visualization logic\n",
    "                if frame_num == 0: # If first frame in sequence, print that you're starting a new data collection and wait 500 ms\n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 8, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, colors[idx], 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(500)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 8, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, colors[idx], 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # Export keypoints (sequence + pose landmarks)\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60c6dbd4-fee4-477c-bfcf-06955a672674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4c6f23-e802-450d-affe-48998d025a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2a8b2a-d7a1-478a-a561-fca453129fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4376568e-72cc-41a1-a736-68623bfe142c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and organize recorded training data\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):         \n",
    "            # LSTM input data\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)  \n",
    "            \n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0ec449-8388-41ed-93b9-b560a032d19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 30, 132) (300, 6)\n"
     ]
    }
   ],
   "source": [
    "# Make sure first dimensions of arrays match\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dde97c00-8f6e-4ae5-8252-3453f0be2329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 30, 132) (270, 6)\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation, and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=15/90, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2114bb0-6056-4e4f-a0af-8bb95cd5d5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks to be used during neural network training \n",
    "#es_callback = EarlyStopping(monitor='val_loss', min_delta=5e-4, patience=10, verbose=0, mode='min')\n",
    "#lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=0, mode='min')\n",
    "#chkpt_callback = ModelCheckpoint(filepath=DATA_PATH, monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                               #  save_weights_only=False, mode='min', save_freq=1)\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# some hyperparamters\n",
    "batch_size = 32\n",
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2108a26a-37f7-4e69-a607-9aaefd8a25f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard logging and callbacks\n",
    "NAME = f\"ExerciseRecognition-LSTM-{int(time.time())}\"\n",
    "log_dir = os.path.join(os.getcwd(), 'logs', NAME,'')\n",
    "#tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#callbacks = [tb_callback, es_callback, lr_callback, chkpt_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d27c363-83d8-4516-9b2e-0522a9e1b4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 128)           133632    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 256)           394240    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750150 (2.86 MB)\n",
      "Trainable params: 750150 (2.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(sequence_length, num_input_values)))\n",
    "lstm.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "lstm.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "lstm.add(Dense(128, activation='relu'))\n",
    "lstm.add(Dense(64, activation='relu'))\n",
    "lstm.add(Dense(actions.shape[0], activation='softmax'))\n",
    "print(lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beeca98f-f93e-478d-af63-56f9df53090a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 8s 245ms/step - loss: 6703663.0000 - categorical_accuracy: 0.1867 - val_loss: 1517361.2500 - val_categorical_accuracy: 0.1333\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 362660.8125 - categorical_accuracy: 0.1689 - val_loss: 100654.6406 - val_categorical_accuracy: 0.1556\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 39865.0898 - categorical_accuracy: 0.1600 - val_loss: 4320.8770 - val_categorical_accuracy: 0.2222\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 6002.6670 - categorical_accuracy: 0.1822 - val_loss: 5904.3828 - val_categorical_accuracy: 0.1556\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 7711.9829 - categorical_accuracy: 0.1956 - val_loss: 5864.0444 - val_categorical_accuracy: 0.1556\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 3496.6697 - categorical_accuracy: 0.1067 - val_loss: 1931.8243 - val_categorical_accuracy: 0.1333\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2279.8354 - categorical_accuracy: 0.1911 - val_loss: 724.8889 - val_categorical_accuracy: 0.0889\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 435.4932 - categorical_accuracy: 0.1822 - val_loss: 647.1247 - val_categorical_accuracy: 0.2000\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 569.7592 - categorical_accuracy: 0.1467 - val_loss: 457.9735 - val_categorical_accuracy: 0.2222\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 667.9248 - categorical_accuracy: 0.1244 - val_loss: 744.0123 - val_categorical_accuracy: 0.1556\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 555.2731 - categorical_accuracy: 0.1733 - val_loss: 365.8465 - val_categorical_accuracy: 0.1556\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 433.1514 - categorical_accuracy: 0.2000 - val_loss: 118.4712 - val_categorical_accuracy: 0.1556\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 117.2390 - categorical_accuracy: 0.1689 - val_loss: 711.7876 - val_categorical_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 438.7953 - categorical_accuracy: 0.2133 - val_loss: 103.2999 - val_categorical_accuracy: 0.1333\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 19959.1426 - categorical_accuracy: 0.1689 - val_loss: 5608.0171 - val_categorical_accuracy: 0.2222\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 5137.2939 - categorical_accuracy: 0.1644 - val_loss: 1111.5376 - val_categorical_accuracy: 0.0889\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1120.5972 - categorical_accuracy: 0.1733 - val_loss: 961.1174 - val_categorical_accuracy: 0.1556\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1268.8003 - categorical_accuracy: 0.1867 - val_loss: 1034.3552 - val_categorical_accuracy: 0.1333\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 542.6795 - categorical_accuracy: 0.1822 - val_loss: 226.7012 - val_categorical_accuracy: 0.1333\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 205.2426 - categorical_accuracy: 0.2089 - val_loss: 192.0772 - val_categorical_accuracy: 0.2222\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 128.9893 - categorical_accuracy: 0.1600 - val_loss: 47.2461 - val_categorical_accuracy: 0.1556\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 34.1257 - categorical_accuracy: 0.1911 - val_loss: 27.8558 - val_categorical_accuracy: 0.1333\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 24.1224 - categorical_accuracy: 0.1733 - val_loss: 14.5145 - val_categorical_accuracy: 0.1333\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 12.1384 - categorical_accuracy: 0.1511 - val_loss: 6.6434 - val_categorical_accuracy: 0.1333\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 6.5996 - categorical_accuracy: 0.1422 - val_loss: 4.2193 - val_categorical_accuracy: 0.1556\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.5875 - categorical_accuracy: 0.1733 - val_loss: 2.9042 - val_categorical_accuracy: 0.0889\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.6468 - categorical_accuracy: 0.1733 - val_loss: 3.2360 - val_categorical_accuracy: 0.2889\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.6750 - categorical_accuracy: 0.2667 - val_loss: 2.2553 - val_categorical_accuracy: 0.2889\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.1562 - categorical_accuracy: 0.2044 - val_loss: 2.0708 - val_categorical_accuracy: 0.2889\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.0826 - categorical_accuracy: 0.2089 - val_loss: 2.3300 - val_categorical_accuracy: 0.2000\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.1273 - categorical_accuracy: 0.2222 - val_loss: 2.1941 - val_categorical_accuracy: 0.3111\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.7891 - categorical_accuracy: 0.2889 - val_loss: 1.7528 - val_categorical_accuracy: 0.2889\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.0144 - categorical_accuracy: 0.2756 - val_loss: 1.8201 - val_categorical_accuracy: 0.2667\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.8411 - categorical_accuracy: 0.2578 - val_loss: 1.9152 - val_categorical_accuracy: 0.2444\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7604 - categorical_accuracy: 0.2667 - val_loss: 1.8535 - val_categorical_accuracy: 0.2889\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.9158 - categorical_accuracy: 0.3644 - val_loss: 1.7276 - val_categorical_accuracy: 0.3556\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7820 - categorical_accuracy: 0.3022 - val_loss: 1.9339 - val_categorical_accuracy: 0.2000\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.9013 - categorical_accuracy: 0.2800 - val_loss: 2.3561 - val_categorical_accuracy: 0.2000\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.0689 - categorical_accuracy: 0.1867 - val_loss: 1.7058 - val_categorical_accuracy: 0.2667\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7625 - categorical_accuracy: 0.3156 - val_loss: 1.8007 - val_categorical_accuracy: 0.2667\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.8206 - categorical_accuracy: 0.3067 - val_loss: 1.7540 - val_categorical_accuracy: 0.1333\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0472 - categorical_accuracy: 0.2178 - val_loss: 1.8684 - val_categorical_accuracy: 0.2889\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.2508 - categorical_accuracy: 0.2089 - val_loss: 2.6899 - val_categorical_accuracy: 0.3111\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.1377 - categorical_accuracy: 0.2267 - val_loss: 1.7765 - val_categorical_accuracy: 0.3778\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.9480 - categorical_accuracy: 0.3289 - val_loss: 1.7356 - val_categorical_accuracy: 0.2000\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7712 - categorical_accuracy: 0.2489 - val_loss: 1.9348 - val_categorical_accuracy: 0.2889\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7663 - categorical_accuracy: 0.2400 - val_loss: 1.8817 - val_categorical_accuracy: 0.2889\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.0328 - categorical_accuracy: 0.2800 - val_loss: 2.5704 - val_categorical_accuracy: 0.2000\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.2516 - categorical_accuracy: 0.2800 - val_loss: 1.8681 - val_categorical_accuracy: 0.2889\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7363 - categorical_accuracy: 0.2667 - val_loss: 2.1679 - val_categorical_accuracy: 0.2889\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.9519 - categorical_accuracy: 0.2756 - val_loss: 2.0443 - val_categorical_accuracy: 0.2000\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.9578 - categorical_accuracy: 0.2578 - val_loss: 1.6952 - val_categorical_accuracy: 0.2222\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.9363 - categorical_accuracy: 0.2044 - val_loss: 2.5570 - val_categorical_accuracy: 0.2889\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.9462 - categorical_accuracy: 0.2978 - val_loss: 1.8432 - val_categorical_accuracy: 0.1778\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.0780 - categorical_accuracy: 0.2222 - val_loss: 2.1452 - val_categorical_accuracy: 0.2000\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.1586 - categorical_accuracy: 0.2178 - val_loss: 1.7442 - val_categorical_accuracy: 0.2000\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.4536 - categorical_accuracy: 0.2444 - val_loss: 4.1883 - val_categorical_accuracy: 0.1556\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.8992 - categorical_accuracy: 0.2400 - val_loss: 1.9986 - val_categorical_accuracy: 0.2000\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0740 - categorical_accuracy: 0.2756 - val_loss: 1.9600 - val_categorical_accuracy: 0.2889\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.8845 - categorical_accuracy: 0.2489 - val_loss: 1.9721 - val_categorical_accuracy: 0.2889\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7746 - categorical_accuracy: 0.4000 - val_loss: 1.7826 - val_categorical_accuracy: 0.2889\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.8157 - categorical_accuracy: 0.3200 - val_loss: 1.7450 - val_categorical_accuracy: 0.2667\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.8246 - categorical_accuracy: 0.2044 - val_loss: 1.6428 - val_categorical_accuracy: 0.2889\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.6262 - categorical_accuracy: 0.2978 - val_loss: 1.7026 - val_categorical_accuracy: 0.3111\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.6200 - categorical_accuracy: 0.3244 - val_loss: 1.7567 - val_categorical_accuracy: 0.2889\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.6596 - categorical_accuracy: 0.2578 - val_loss: 1.9695 - val_categorical_accuracy: 0.2000\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.9112 - categorical_accuracy: 0.2800 - val_loss: 1.5990 - val_categorical_accuracy: 0.3111\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.6420 - categorical_accuracy: 0.2578 - val_loss: 1.6881 - val_categorical_accuracy: 0.2889\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.6847 - categorical_accuracy: 0.2667 - val_loss: 2.0689 - val_categorical_accuracy: 0.2889\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7000 - categorical_accuracy: 0.2489 - val_loss: 1.5975 - val_categorical_accuracy: 0.2889\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.6475 - categorical_accuracy: 0.3511 - val_loss: 1.5887 - val_categorical_accuracy: 0.3111\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.6591 - categorical_accuracy: 0.3511 - val_loss: 1.6439 - val_categorical_accuracy: 0.3111\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7758 - categorical_accuracy: 0.2000 - val_loss: 2.1664 - val_categorical_accuracy: 0.2000\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.2143 - categorical_accuracy: 0.2622 - val_loss: 1.6805 - val_categorical_accuracy: 0.2000\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.4521 - categorical_accuracy: 0.2267 - val_loss: 1.8467 - val_categorical_accuracy: 0.3111\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.0768 - categorical_accuracy: 0.2444 - val_loss: 2.5527 - val_categorical_accuracy: 0.3111\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.9880 - categorical_accuracy: 0.2622 - val_loss: 1.8689 - val_categorical_accuracy: 0.2889\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.9353 - categorical_accuracy: 0.3511 - val_loss: 2.6347 - val_categorical_accuracy: 0.2000\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.5319 - categorical_accuracy: 0.2489 - val_loss: 2.5199 - val_categorical_accuracy: 0.3111\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.9853 - categorical_accuracy: 0.2933 - val_loss: 1.7614 - val_categorical_accuracy: 0.3333\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7808 - categorical_accuracy: 0.3289 - val_loss: 1.6635 - val_categorical_accuracy: 0.3556\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.8050 - categorical_accuracy: 0.2622 - val_loss: 1.5778 - val_categorical_accuracy: 0.2667\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.8068 - categorical_accuracy: 0.2533 - val_loss: 1.6231 - val_categorical_accuracy: 0.3111\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7963 - categorical_accuracy: 0.2844 - val_loss: 1.9313 - val_categorical_accuracy: 0.2222\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.9939 - categorical_accuracy: 0.2000 - val_loss: 2.8778 - val_categorical_accuracy: 0.2444\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.0525 - categorical_accuracy: 0.2933 - val_loss: 1.6678 - val_categorical_accuracy: 0.2222\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7141 - categorical_accuracy: 0.3289 - val_loss: 1.8012 - val_categorical_accuracy: 0.3111\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7325 - categorical_accuracy: 0.2889 - val_loss: 1.6049 - val_categorical_accuracy: 0.2222\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.6143 - categorical_accuracy: 0.2978 - val_loss: 2.3273 - val_categorical_accuracy: 0.2000\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 2.2544 - categorical_accuracy: 0.2489 - val_loss: 2.3803 - val_categorical_accuracy: 0.2889\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.1679 - categorical_accuracy: 0.2356 - val_loss: 1.7994 - val_categorical_accuracy: 0.2000\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.8101 - categorical_accuracy: 0.2978 - val_loss: 1.9109 - val_categorical_accuracy: 0.2667\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 2.0164 - categorical_accuracy: 0.2578 - val_loss: 1.9593 - val_categorical_accuracy: 0.2222\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7653 - categorical_accuracy: 0.2844 - val_loss: 2.3305 - val_categorical_accuracy: 0.2000\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.2480 - categorical_accuracy: 0.2400 - val_loss: 2.6113 - val_categorical_accuracy: 0.3111\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.9073 - categorical_accuracy: 0.3156 - val_loss: 1.8258 - val_categorical_accuracy: 0.2222\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 2.0312 - categorical_accuracy: 0.2000 - val_loss: 1.7959 - val_categorical_accuracy: 0.2889\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.9733 - categorical_accuracy: 0.1911 - val_loss: 1.8174 - val_categorical_accuracy: 0.2889\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.8285 - categorical_accuracy: 0.3156 - val_loss: 1.5291 - val_categorical_accuracy: 0.3556\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.6493 - categorical_accuracy: 0.2356 - val_loss: 1.9570 - val_categorical_accuracy: 0.2889\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7470 - categorical_accuracy: 0.3289 - val_loss: 1.8266 - val_categorical_accuracy: 0.2000\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.0505 - categorical_accuracy: 0.2711 - val_loss: 2.0175 - val_categorical_accuracy: 0.3111\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.0296 - categorical_accuracy: 0.3733 - val_loss: 1.9464 - val_categorical_accuracy: 0.1556\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.0154 - categorical_accuracy: 0.2267 - val_loss: 2.8239 - val_categorical_accuracy: 0.3111\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.2524 - categorical_accuracy: 0.2933 - val_loss: 1.6495 - val_categorical_accuracy: 0.2444\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.7299 - categorical_accuracy: 0.3378 - val_loss: 1.9158 - val_categorical_accuracy: 0.2444\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.8817 - categorical_accuracy: 0.2800 - val_loss: 1.7626 - val_categorical_accuracy: 0.3333\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.0473 - categorical_accuracy: 0.3378 - val_loss: 2.0009 - val_categorical_accuracy: 0.2667\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7084 - categorical_accuracy: 0.2756 - val_loss: 1.7122 - val_categorical_accuracy: 0.3333\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.6427 - categorical_accuracy: 0.3333 - val_loss: 2.2518 - val_categorical_accuracy: 0.3111\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.9241 - categorical_accuracy: 0.3200 - val_loss: 1.8878 - val_categorical_accuracy: 0.2889\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.8012 - categorical_accuracy: 0.2800 - val_loss: 1.5442 - val_categorical_accuracy: 0.4000\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.6895 - categorical_accuracy: 0.1689 - val_loss: 1.7540 - val_categorical_accuracy: 0.2667\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.6297 - categorical_accuracy: 0.2933 - val_loss: 1.7084 - val_categorical_accuracy: 0.3111\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7690 - categorical_accuracy: 0.3289 - val_loss: 1.5252 - val_categorical_accuracy: 0.4000\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.7539 - categorical_accuracy: 0.1911 - val_loss: 1.9720 - val_categorical_accuracy: 0.3111\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.8939 - categorical_accuracy: 0.2844 - val_loss: 1.7398 - val_categorical_accuracy: 0.3111\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.6092 - categorical_accuracy: 0.2889 - val_loss: 1.7457 - val_categorical_accuracy: 0.2000\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.9865 - categorical_accuracy: 0.2489 - val_loss: 2.1503 - val_categorical_accuracy: 0.2889\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.9834 - categorical_accuracy: 0.3244 - val_loss: 1.7939 - val_categorical_accuracy: 0.2889\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 2.0986 - categorical_accuracy: 0.2089 - val_loss: 2.1260 - val_categorical_accuracy: 0.2889\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 2.0515 - categorical_accuracy: 0.3422 - val_loss: 2.4810 - val_categorical_accuracy: 0.2000\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.7529 - categorical_accuracy: 0.1911 - val_loss: 1.7952 - val_categorical_accuracy: 0.2000\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.2995 - categorical_accuracy: 0.2933 - val_loss: 2.0775 - val_categorical_accuracy: 0.3111\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7382 - categorical_accuracy: 0.1911 - val_loss: 1.6070 - val_categorical_accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.6774 - categorical_accuracy: 0.2578 - val_loss: 1.5169 - val_categorical_accuracy: 0.4000\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.6878 - categorical_accuracy: 0.2800 - val_loss: 1.7871 - val_categorical_accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.6127 - categorical_accuracy: 0.3111 - val_loss: 1.5800 - val_categorical_accuracy: 0.2000\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.5589 - categorical_accuracy: 0.2711 - val_loss: 1.6858 - val_categorical_accuracy: 0.2889\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5602 - categorical_accuracy: 0.3378 - val_loss: 1.4837 - val_categorical_accuracy: 0.4222\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.5021 - categorical_accuracy: 0.3911 - val_loss: 1.7027 - val_categorical_accuracy: 0.3778\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.8425 - categorical_accuracy: 0.2933 - val_loss: 1.8237 - val_categorical_accuracy: 0.3556\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7213 - categorical_accuracy: 0.2933 - val_loss: 1.5749 - val_categorical_accuracy: 0.2667\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7983 - categorical_accuracy: 0.2000 - val_loss: 1.8641 - val_categorical_accuracy: 0.3111\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.5842 - categorical_accuracy: 0.3156 - val_loss: 1.6477 - val_categorical_accuracy: 0.3778\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.7110 - categorical_accuracy: 0.3156 - val_loss: 1.7622 - val_categorical_accuracy: 0.2889\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.5326 - categorical_accuracy: 0.3556 - val_loss: 1.6070 - val_categorical_accuracy: 0.1556\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7380 - categorical_accuracy: 0.2133 - val_loss: 1.5080 - val_categorical_accuracy: 0.2667\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7905 - categorical_accuracy: 0.2400 - val_loss: 1.8631 - val_categorical_accuracy: 0.3111\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.9146 - categorical_accuracy: 0.3333 - val_loss: 1.9006 - val_categorical_accuracy: 0.2889\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.5453 - categorical_accuracy: 0.3067 - val_loss: 1.5117 - val_categorical_accuracy: 0.4222\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.6158 - categorical_accuracy: 0.3511 - val_loss: 2.2690 - val_categorical_accuracy: 0.3111\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.8644 - categorical_accuracy: 0.3422 - val_loss: 1.6121 - val_categorical_accuracy: 0.3111\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7485 - categorical_accuracy: 0.3111 - val_loss: 1.5233 - val_categorical_accuracy: 0.3556\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.6662 - categorical_accuracy: 0.2933 - val_loss: 1.7922 - val_categorical_accuracy: 0.2889\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.6409 - categorical_accuracy: 0.3200 - val_loss: 1.5764 - val_categorical_accuracy: 0.3778\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.5875 - categorical_accuracy: 0.3422 - val_loss: 1.6549 - val_categorical_accuracy: 0.3111\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.5197 - categorical_accuracy: 0.3644 - val_loss: 1.6568 - val_categorical_accuracy: 0.3111\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.6194 - categorical_accuracy: 0.3556 - val_loss: 1.4663 - val_categorical_accuracy: 0.4000\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.5138 - categorical_accuracy: 0.3200 - val_loss: 1.5422 - val_categorical_accuracy: 0.2667\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.5424 - categorical_accuracy: 0.3333 - val_loss: 1.6600 - val_categorical_accuracy: 0.2889\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 1.6230 - categorical_accuracy: 0.3378 - val_loss: 1.7487 - val_categorical_accuracy: 0.1333\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.8880 - categorical_accuracy: 0.2089 - val_loss: 1.6903 - val_categorical_accuracy: 0.2889\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7185 - categorical_accuracy: 0.2933 - val_loss: 1.6953 - val_categorical_accuracy: 0.2889\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7032 - categorical_accuracy: 0.3022 - val_loss: 1.6834 - val_categorical_accuracy: 0.3111\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.6360 - categorical_accuracy: 0.2800 - val_loss: 1.4836 - val_categorical_accuracy: 0.2444\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.5675 - categorical_accuracy: 0.3556 - val_loss: 1.7422 - val_categorical_accuracy: 0.2889\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.5959 - categorical_accuracy: 0.3511 - val_loss: 1.6601 - val_categorical_accuracy: 0.2889\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7068 - categorical_accuracy: 0.3289 - val_loss: 1.6823 - val_categorical_accuracy: 0.2000\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7052 - categorical_accuracy: 0.2311 - val_loss: 1.7892 - val_categorical_accuracy: 0.3333\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.6465 - categorical_accuracy: 0.3422 - val_loss: 1.6798 - val_categorical_accuracy: 0.3111\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7395 - categorical_accuracy: 0.3022 - val_loss: 2.0172 - val_categorical_accuracy: 0.3333\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.8910 - categorical_accuracy: 0.2800 - val_loss: 1.6411 - val_categorical_accuracy: 0.2889\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7432 - categorical_accuracy: 0.3378 - val_loss: 1.7562 - val_categorical_accuracy: 0.3556\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7097 - categorical_accuracy: 0.2844 - val_loss: 1.6414 - val_categorical_accuracy: 0.3333\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.6792 - categorical_accuracy: 0.2711 - val_loss: 1.8853 - val_categorical_accuracy: 0.3111\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7814 - categorical_accuracy: 0.2667 - val_loss: 1.7685 - val_categorical_accuracy: 0.3111\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.1167 - categorical_accuracy: 0.3156 - val_loss: 1.7043 - val_categorical_accuracy: 0.3333\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.6000 - categorical_accuracy: 0.3333 - val_loss: 1.5647 - val_categorical_accuracy: 0.3333\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.7695 - categorical_accuracy: 0.2711 - val_loss: 1.7205 - val_categorical_accuracy: 0.2889\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.6195 - categorical_accuracy: 0.3244 - val_loss: 1.5899 - val_categorical_accuracy: 0.3111\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.5157 - categorical_accuracy: 0.3911 - val_loss: 1.6036 - val_categorical_accuracy: 0.3333\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.5803 - categorical_accuracy: 0.3422 - val_loss: 1.6508 - val_categorical_accuracy: 0.3111\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.5481 - categorical_accuracy: 0.3467 - val_loss: 1.4971 - val_categorical_accuracy: 0.2889\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.5695 - categorical_accuracy: 0.3333 - val_loss: 1.5493 - val_categorical_accuracy: 0.2889\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.4754 - categorical_accuracy: 0.3644 - val_loss: 1.8117 - val_categorical_accuracy: 0.3333\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.6177 - categorical_accuracy: 0.3289 - val_loss: 1.6133 - val_categorical_accuracy: 0.1556\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.5456 - categorical_accuracy: 0.2978 - val_loss: 1.7167 - val_categorical_accuracy: 0.3333\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.5164 - categorical_accuracy: 0.3778 - val_loss: 1.5099 - val_categorical_accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.4922 - categorical_accuracy: 0.3156 - val_loss: 1.5127 - val_categorical_accuracy: 0.2889\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.5536 - categorical_accuracy: 0.3244 - val_loss: 1.6410 - val_categorical_accuracy: 0.3111\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.8541 - categorical_accuracy: 0.3111 - val_loss: 1.7315 - val_categorical_accuracy: 0.3556\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.5755 - categorical_accuracy: 0.3467 - val_loss: 1.6352 - val_categorical_accuracy: 0.1778\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7128 - categorical_accuracy: 0.3067 - val_loss: 2.2651 - val_categorical_accuracy: 0.3111\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.8024 - categorical_accuracy: 0.3333 - val_loss: 1.5055 - val_categorical_accuracy: 0.4444\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.7353 - categorical_accuracy: 0.3422 - val_loss: 1.5062 - val_categorical_accuracy: 0.3778\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7196 - categorical_accuracy: 0.2711 - val_loss: 2.3895 - val_categorical_accuracy: 0.2889\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.9826 - categorical_accuracy: 0.3422 - val_loss: 1.6885 - val_categorical_accuracy: 0.2444\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.9775 - categorical_accuracy: 0.2133 - val_loss: 2.0399 - val_categorical_accuracy: 0.2889\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.7107 - categorical_accuracy: 0.3289 - val_loss: 1.5564 - val_categorical_accuracy: 0.3333\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.5752 - categorical_accuracy: 0.3289 - val_loss: 1.4950 - val_categorical_accuracy: 0.2889\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.9042 - categorical_accuracy: 0.2978 - val_loss: 2.2665 - val_categorical_accuracy: 0.3333\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.9060 - categorical_accuracy: 0.2400 - val_loss: 1.6468 - val_categorical_accuracy: 0.2889\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.8133 - categorical_accuracy: 0.2533 - val_loss: 1.7566 - val_categorical_accuracy: 0.3111\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.7368 - categorical_accuracy: 0.3467 - val_loss: 1.7212 - val_categorical_accuracy: 0.3111\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.6247 - categorical_accuracy: 0.3467 - val_loss: 1.5922 - val_categorical_accuracy: 0.3556\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.6426 - categorical_accuracy: 0.3333 - val_loss: 1.7264 - val_categorical_accuracy: 0.2444\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7020 - categorical_accuracy: 0.2800 - val_loss: 1.5340 - val_categorical_accuracy: 0.3556\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 2.5488 - categorical_accuracy: 0.2711 - val_loss: 2.3217 - val_categorical_accuracy: 0.1556\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.0365 - categorical_accuracy: 0.1556 - val_loss: 1.6841 - val_categorical_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x251e67ee050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "lstm.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7ef533-9f4d-4e8d-a773-fe93f2f631fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard logging and callbacks\n",
    "NAME = f\"ExerciseRecognition-AttnLSTM-{int(time.time())}\"\n",
    "log_dir = os.path.join(os.getcwd(), 'logs', NAME,'')\n",
    "#tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#callbacks = [tb_callback, es_callback, lr_callback, chkpt_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a9d650-28a2-4605-906a-7ad92c708b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention_block(inputs, time_steps):\n",
    "    \"\"\"\n",
    "    Attention layer for deep neural network\n",
    "    \n",
    "    \"\"\"\n",
    "    # Attention weights\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(time_steps, activation='softmax')(a)\n",
    "    \n",
    "    # Attention vector\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    \n",
    "    # Luong's multiplicative score\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul') \n",
    "    \n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89973d6a-bc65-4d69-a8cf-f981bd67d989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 132)]            0         []                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 30, 512)              796672    ['input_1[0][0]']             \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 512, 30)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512, 30)              930       ['permute[0][0]']             \n",
      "                                                                                                  \n",
      " attention_vec (Permute)     (None, 30, 512)              0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " attention_mul (Multiply)    (None, 30, 512)              0         ['bidirectional[0][0]',       \n",
      "                                                                     'attention_vec[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 15360)                0         ['attention_mul[0][0]']       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  7864832   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    3078      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8665512 (33.06 MB)\n",
      "Trainable params: 8665512 (33.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = 256\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=(sequence_length, num_input_values))\n",
    "\n",
    "# Bi-LSTM\n",
    "lstm_out = Bidirectional(LSTM(HIDDEN_UNITS, return_sequences=True))(inputs)\n",
    "\n",
    "# Attention\n",
    "attention_mul = attention_block(lstm_out, sequence_length)\n",
    "attention_mul = Flatten()(attention_mul)\n",
    "\n",
    "# Fully Connected Layer\n",
    "x = Dense(2*HIDDEN_UNITS, activation='relu')(attention_mul)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output\n",
    "x = Dense(actions.shape[0], activation='softmax')(x)\n",
    "\n",
    "# Bring it all together\n",
    "AttnLSTM = Model(inputs=[inputs], outputs=x)\n",
    "print(AttnLSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45e5a32-5f14-48c5-84ed-067fdc4bbf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 10s 394ms/step - loss: 1.6044 - categorical_accuracy: 0.3289 - val_loss: 1.3649 - val_categorical_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.1624 - categorical_accuracy: 0.5111 - val_loss: 0.7735 - val_categorical_accuracy: 0.7556\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.7768 - categorical_accuracy: 0.6978 - val_loss: 0.4742 - val_categorical_accuracy: 0.7778\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.5739 - categorical_accuracy: 0.7600 - val_loss: 0.3649 - val_categorical_accuracy: 0.8222\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.5908 - categorical_accuracy: 0.7244 - val_loss: 0.5145 - val_categorical_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.7518 - categorical_accuracy: 0.7156 - val_loss: 0.9613 - val_categorical_accuracy: 0.6000\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.7858 - categorical_accuracy: 0.7022 - val_loss: 0.5179 - val_categorical_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.7318 - categorical_accuracy: 0.7333 - val_loss: 0.3434 - val_categorical_accuracy: 0.8222\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.5314 - categorical_accuracy: 0.7467 - val_loss: 0.4155 - val_categorical_accuracy: 0.7556\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.5372 - categorical_accuracy: 0.7600 - val_loss: 0.3874 - val_categorical_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.4925 - categorical_accuracy: 0.7467 - val_loss: 0.3598 - val_categorical_accuracy: 0.7778\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.4216 - categorical_accuracy: 0.8178 - val_loss: 0.3332 - val_categorical_accuracy: 0.9333\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.3566 - categorical_accuracy: 0.8444 - val_loss: 0.3039 - val_categorical_accuracy: 0.8667\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.3583 - categorical_accuracy: 0.8533 - val_loss: 0.2835 - val_categorical_accuracy: 0.8889\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.2861 - categorical_accuracy: 0.8978 - val_loss: 0.3616 - val_categorical_accuracy: 0.7778\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.5219 - categorical_accuracy: 0.7911 - val_loss: 0.2923 - val_categorical_accuracy: 0.8222\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.4004 - categorical_accuracy: 0.7956 - val_loss: 0.3123 - val_categorical_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.3649 - categorical_accuracy: 0.8044 - val_loss: 0.2586 - val_categorical_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.4212 - categorical_accuracy: 0.7778 - val_loss: 0.3297 - val_categorical_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.3357 - categorical_accuracy: 0.8578 - val_loss: 0.2615 - val_categorical_accuracy: 0.9333\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.3125 - categorical_accuracy: 0.8711 - val_loss: 0.2855 - val_categorical_accuracy: 0.8667\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.3184 - categorical_accuracy: 0.8667 - val_loss: 0.3205 - val_categorical_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.3518 - categorical_accuracy: 0.8533 - val_loss: 0.4294 - val_categorical_accuracy: 0.7778\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3496 - categorical_accuracy: 0.8489 - val_loss: 0.2678 - val_categorical_accuracy: 0.8444\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.2767 - categorical_accuracy: 0.8711 - val_loss: 0.2311 - val_categorical_accuracy: 0.8889\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.3185 - categorical_accuracy: 0.8844 - val_loss: 0.3659 - val_categorical_accuracy: 0.8667\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.4850 - categorical_accuracy: 0.8178 - val_loss: 0.3384 - val_categorical_accuracy: 0.8667\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.4836 - categorical_accuracy: 0.8133 - val_loss: 0.2670 - val_categorical_accuracy: 0.9333\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.3032 - categorical_accuracy: 0.8889 - val_loss: 0.1967 - val_categorical_accuracy: 0.8889\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.2371 - categorical_accuracy: 0.9111 - val_loss: 0.1835 - val_categorical_accuracy: 0.9333\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.4089 - categorical_accuracy: 0.8533 - val_loss: 0.4221 - val_categorical_accuracy: 0.8222\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.3730 - categorical_accuracy: 0.8800 - val_loss: 0.1965 - val_categorical_accuracy: 0.8889\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.2277 - categorical_accuracy: 0.9067 - val_loss: 0.1977 - val_categorical_accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1850 - categorical_accuracy: 0.9333 - val_loss: 0.1144 - val_categorical_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1938 - categorical_accuracy: 0.9200 - val_loss: 0.2657 - val_categorical_accuracy: 0.8889\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.3013 - categorical_accuracy: 0.8889 - val_loss: 0.1683 - val_categorical_accuracy: 0.9556\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.2050 - categorical_accuracy: 0.9422 - val_loss: 0.2671 - val_categorical_accuracy: 0.8889\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2071 - categorical_accuracy: 0.9289 - val_loss: 0.0899 - val_categorical_accuracy: 0.9778\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.1634 - categorical_accuracy: 0.9378 - val_loss: 0.1407 - val_categorical_accuracy: 0.9111\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.1938 - categorical_accuracy: 0.9289 - val_loss: 0.0829 - val_categorical_accuracy: 0.9556\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.1565 - categorical_accuracy: 0.9422 - val_loss: 0.1063 - val_categorical_accuracy: 0.9556\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.2236 - categorical_accuracy: 0.9200 - val_loss: 0.0891 - val_categorical_accuracy: 0.9778\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1711 - categorical_accuracy: 0.9422 - val_loss: 0.1309 - val_categorical_accuracy: 0.9556\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.1438 - categorical_accuracy: 0.9422 - val_loss: 0.1692 - val_categorical_accuracy: 0.9556\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1069 - categorical_accuracy: 0.9644 - val_loss: 0.0879 - val_categorical_accuracy: 0.9778\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0897 - categorical_accuracy: 0.9689 - val_loss: 0.1232 - val_categorical_accuracy: 0.9778\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0783 - categorical_accuracy: 0.9778 - val_loss: 0.1674 - val_categorical_accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1421 - categorical_accuracy: 0.9467 - val_loss: 0.1056 - val_categorical_accuracy: 0.9556\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.2078 - categorical_accuracy: 0.9111 - val_loss: 0.1068 - val_categorical_accuracy: 0.9556\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1191 - categorical_accuracy: 0.9378 - val_loss: 0.0738 - val_categorical_accuracy: 0.9778\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0675 - categorical_accuracy: 0.9778 - val_loss: 0.1046 - val_categorical_accuracy: 0.9333\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0838 - categorical_accuracy: 0.9644 - val_loss: 0.0680 - val_categorical_accuracy: 0.9778\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0501 - categorical_accuracy: 0.9867 - val_loss: 0.0586 - val_categorical_accuracy: 0.9778\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0824 - categorical_accuracy: 0.9689 - val_loss: 0.1058 - val_categorical_accuracy: 0.9333\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.1113 - categorical_accuracy: 0.9600 - val_loss: 0.2581 - val_categorical_accuracy: 0.9111\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.1723 - categorical_accuracy: 0.9200 - val_loss: 0.1000 - val_categorical_accuracy: 0.9333\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.1354 - categorical_accuracy: 0.9556 - val_loss: 0.1053 - val_categorical_accuracy: 0.9556\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0867 - categorical_accuracy: 0.9689 - val_loss: 0.0571 - val_categorical_accuracy: 0.9778\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0554 - categorical_accuracy: 0.9822 - val_loss: 0.0632 - val_categorical_accuracy: 0.9778\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0463 - categorical_accuracy: 0.9911 - val_loss: 0.0866 - val_categorical_accuracy: 0.9778\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0408 - categorical_accuracy: 0.9911 - val_loss: 0.1236 - val_categorical_accuracy: 0.9556\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 0.0308 - categorical_accuracy: 0.9956 - val_loss: 0.0963 - val_categorical_accuracy: 0.9778\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0460 - categorical_accuracy: 0.9822 - val_loss: 0.1962 - val_categorical_accuracy: 0.9111\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1425 - categorical_accuracy: 0.9556 - val_loss: 0.1227 - val_categorical_accuracy: 0.9556\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.0844 - categorical_accuracy: 0.9689 - val_loss: 0.1956 - val_categorical_accuracy: 0.9333\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0959 - categorical_accuracy: 0.9644 - val_loss: 0.0961 - val_categorical_accuracy: 0.9778\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.1140 - categorical_accuracy: 0.9644 - val_loss: 0.2345 - val_categorical_accuracy: 0.9333\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0891 - categorical_accuracy: 0.9600 - val_loss: 0.2567 - val_categorical_accuracy: 0.8667\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.3542 - categorical_accuracy: 0.8578 - val_loss: 0.2002 - val_categorical_accuracy: 0.9111\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.3416 - categorical_accuracy: 0.7333 - val_loss: 0.9013 - val_categorical_accuracy: 0.6667\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.9017 - categorical_accuracy: 0.7644 - val_loss: 0.5922 - val_categorical_accuracy: 0.7778\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.4307 - categorical_accuracy: 0.8267 - val_loss: 0.2038 - val_categorical_accuracy: 0.9333\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.2784 - categorical_accuracy: 0.8978 - val_loss: 0.1587 - val_categorical_accuracy: 0.9556\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.3141 - categorical_accuracy: 0.9067 - val_loss: 0.2083 - val_categorical_accuracy: 0.9111\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1968 - categorical_accuracy: 0.9156 - val_loss: 0.0993 - val_categorical_accuracy: 0.9556\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1288 - categorical_accuracy: 0.9644 - val_loss: 0.1931 - val_categorical_accuracy: 0.9556\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.2994 - categorical_accuracy: 0.9111 - val_loss: 0.1305 - val_categorical_accuracy: 0.9556\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.1926 - categorical_accuracy: 0.9422 - val_loss: 0.1178 - val_categorical_accuracy: 0.9556\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1466 - categorical_accuracy: 0.9511 - val_loss: 0.0685 - val_categorical_accuracy: 0.9778\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.1175 - categorical_accuracy: 0.9733 - val_loss: 0.1252 - val_categorical_accuracy: 0.9778\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.4971 - categorical_accuracy: 0.8222 - val_loss: 0.2940 - val_categorical_accuracy: 0.8667\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.2875 - categorical_accuracy: 0.8978 - val_loss: 0.1993 - val_categorical_accuracy: 0.9111\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.2089 - categorical_accuracy: 0.9244 - val_loss: 0.1787 - val_categorical_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.1811 - categorical_accuracy: 0.9333 - val_loss: 0.1165 - val_categorical_accuracy: 0.9556\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1143 - categorical_accuracy: 0.9689 - val_loss: 0.0491 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0778 - categorical_accuracy: 0.9822 - val_loss: 0.0788 - val_categorical_accuracy: 0.9778\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0685 - categorical_accuracy: 0.9778 - val_loss: 0.1034 - val_categorical_accuracy: 0.9556\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0735 - categorical_accuracy: 0.9822 - val_loss: 0.0600 - val_categorical_accuracy: 0.9778\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0752 - categorical_accuracy: 0.9733 - val_loss: 0.0711 - val_categorical_accuracy: 0.9556\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0614 - categorical_accuracy: 0.9867 - val_loss: 0.0465 - val_categorical_accuracy: 0.9778\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.1323 - categorical_accuracy: 0.9600 - val_loss: 0.0394 - val_categorical_accuracy: 0.9778\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0753 - categorical_accuracy: 0.9733 - val_loss: 0.0482 - val_categorical_accuracy: 0.9778\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0621 - categorical_accuracy: 0.9733 - val_loss: 0.1043 - val_categorical_accuracy: 0.9556\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0651 - categorical_accuracy: 0.9689 - val_loss: 0.0810 - val_categorical_accuracy: 0.9778\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0562 - categorical_accuracy: 0.9822 - val_loss: 0.0831 - val_categorical_accuracy: 0.9556\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0542 - categorical_accuracy: 0.9733 - val_loss: 0.0750 - val_categorical_accuracy: 0.9778\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0383 - categorical_accuracy: 0.9867 - val_loss: 0.0852 - val_categorical_accuracy: 0.9556\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0347 - categorical_accuracy: 0.9911 - val_loss: 0.0668 - val_categorical_accuracy: 0.9778\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0336 - categorical_accuracy: 0.9867 - val_loss: 0.0627 - val_categorical_accuracy: 0.9778\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.0196 - categorical_accuracy: 0.9911 - val_loss: 0.0606 - val_categorical_accuracy: 0.9778\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0251 - categorical_accuracy: 0.9956 - val_loss: 0.0696 - val_categorical_accuracy: 0.9778\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0185 - categorical_accuracy: 0.9956 - val_loss: 0.0555 - val_categorical_accuracy: 0.9778\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0157 - categorical_accuracy: 0.9956 - val_loss: 0.0633 - val_categorical_accuracy: 0.9778\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0120 - categorical_accuracy: 0.9956 - val_loss: 0.0927 - val_categorical_accuracy: 0.9778\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0241 - categorical_accuracy: 0.9956 - val_loss: 0.1005 - val_categorical_accuracy: 0.9556\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.0233 - categorical_accuracy: 0.9911 - val_loss: 0.0637 - val_categorical_accuracy: 0.9778\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0112 - categorical_accuracy: 1.0000 - val_loss: 0.0631 - val_categorical_accuracy: 0.9556\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0079 - categorical_accuracy: 1.0000 - val_loss: 0.0736 - val_categorical_accuracy: 0.9778\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.0922 - val_categorical_accuracy: 0.9556\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0086 - categorical_accuracy: 1.0000 - val_loss: 0.0815 - val_categorical_accuracy: 0.9778\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0103 - categorical_accuracy: 0.9956 - val_loss: 0.0745 - val_categorical_accuracy: 0.9778\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0069 - categorical_accuracy: 0.9956 - val_loss: 0.1123 - val_categorical_accuracy: 0.9556\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.1018 - val_categorical_accuracy: 0.9556\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0058 - categorical_accuracy: 1.0000 - val_loss: 0.0804 - val_categorical_accuracy: 0.9778\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0079 - categorical_accuracy: 1.0000 - val_loss: 0.0826 - val_categorical_accuracy: 0.9556\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0069 - categorical_accuracy: 1.0000 - val_loss: 0.0903 - val_categorical_accuracy: 0.9556\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.1075 - val_categorical_accuracy: 0.9556\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.0859 - val_categorical_accuracy: 0.9556\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.0764 - val_categorical_accuracy: 0.9778\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.1130 - val_categorical_accuracy: 0.9556\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0041 - categorical_accuracy: 1.0000 - val_loss: 0.1090 - val_categorical_accuracy: 0.9556\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.0910 - val_categorical_accuracy: 0.9556\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.1108 - val_categorical_accuracy: 0.9556\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 0.1031 - val_categorical_accuracy: 0.9778\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0368 - categorical_accuracy: 0.9867 - val_loss: 0.0891 - val_categorical_accuracy: 0.9556\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0369 - categorical_accuracy: 0.9867 - val_loss: 0.1126 - val_categorical_accuracy: 0.9778\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.0429 - categorical_accuracy: 0.9822 - val_loss: 0.1447 - val_categorical_accuracy: 0.9556\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0137 - categorical_accuracy: 1.0000 - val_loss: 0.1041 - val_categorical_accuracy: 0.9778\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0351 - categorical_accuracy: 0.9956 - val_loss: 0.0866 - val_categorical_accuracy: 0.9556\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0572 - categorical_accuracy: 0.9689 - val_loss: 0.0663 - val_categorical_accuracy: 0.9778\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0327 - categorical_accuracy: 0.9911 - val_loss: 0.1083 - val_categorical_accuracy: 0.9778\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0396 - categorical_accuracy: 0.9822 - val_loss: 0.0652 - val_categorical_accuracy: 0.9778\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0350 - categorical_accuracy: 0.9911 - val_loss: 0.1115 - val_categorical_accuracy: 0.9778\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0387 - categorical_accuracy: 0.9911 - val_loss: 0.0502 - val_categorical_accuracy: 0.9556\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0219 - categorical_accuracy: 0.9956 - val_loss: 0.0792 - val_categorical_accuracy: 0.9778\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0134 - categorical_accuracy: 1.0000 - val_loss: 0.1227 - val_categorical_accuracy: 0.9556\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.0106 - categorical_accuracy: 1.0000 - val_loss: 0.0767 - val_categorical_accuracy: 0.9556\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0141 - categorical_accuracy: 0.9956 - val_loss: 0.0703 - val_categorical_accuracy: 0.9778\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0111 - categorical_accuracy: 1.0000 - val_loss: 0.0763 - val_categorical_accuracy: 0.9556\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0099 - categorical_accuracy: 1.0000 - val_loss: 0.0449 - val_categorical_accuracy: 0.9778\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0058 - categorical_accuracy: 1.0000 - val_loss: 0.0427 - val_categorical_accuracy: 0.9778\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.0553 - val_categorical_accuracy: 0.9778\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.1300 - val_categorical_accuracy: 0.9556\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0257 - categorical_accuracy: 0.9956 - val_loss: 0.0832 - val_categorical_accuracy: 0.9778\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 0.0471 - val_categorical_accuracy: 0.9778\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 0.0559 - val_categorical_accuracy: 0.9778\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0061 - categorical_accuracy: 1.0000 - val_loss: 0.0715 - val_categorical_accuracy: 0.9778\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.0993 - val_categorical_accuracy: 0.9556\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0284 - categorical_accuracy: 0.9911 - val_loss: 0.0770 - val_categorical_accuracy: 0.9778\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0503 - categorical_accuracy: 0.9867 - val_loss: 0.1069 - val_categorical_accuracy: 0.9778\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0195 - categorical_accuracy: 0.9956 - val_loss: 0.0444 - val_categorical_accuracy: 0.9778\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0548 - categorical_accuracy: 0.9778 - val_loss: 0.0282 - val_categorical_accuracy: 0.9778\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0438 - categorical_accuracy: 0.9867 - val_loss: 0.2869 - val_categorical_accuracy: 0.9333\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.2442 - categorical_accuracy: 0.9378 - val_loss: 0.2798 - val_categorical_accuracy: 0.9111\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1578 - categorical_accuracy: 0.9422 - val_loss: 0.0807 - val_categorical_accuracy: 0.9556\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0420 - categorical_accuracy: 0.9911 - val_loss: 0.0300 - val_categorical_accuracy: 0.9778\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0245 - categorical_accuracy: 0.9867 - val_loss: 0.1436 - val_categorical_accuracy: 0.9778\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.0721 - categorical_accuracy: 0.9778 - val_loss: 0.1542 - val_categorical_accuracy: 0.9556\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0488 - categorical_accuracy: 0.9867 - val_loss: 0.0433 - val_categorical_accuracy: 0.9778\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0607 - categorical_accuracy: 0.9689 - val_loss: 0.0903 - val_categorical_accuracy: 0.9556\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.1482 - categorical_accuracy: 0.9556 - val_loss: 0.3077 - val_categorical_accuracy: 0.8889\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.6844 - categorical_accuracy: 0.7733 - val_loss: 0.4423 - val_categorical_accuracy: 0.8222\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.5919 - categorical_accuracy: 0.7511 - val_loss: 0.1431 - val_categorical_accuracy: 0.9556\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.2117 - categorical_accuracy: 0.9511 - val_loss: 0.4355 - val_categorical_accuracy: 0.8222\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.3148 - categorical_accuracy: 0.6489 - val_loss: 0.3302 - val_categorical_accuracy: 0.8222\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.7079 - categorical_accuracy: 0.7511 - val_loss: 0.3069 - val_categorical_accuracy: 0.8444\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.5336 - categorical_accuracy: 0.7644 - val_loss: 0.1900 - val_categorical_accuracy: 0.9778\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.2639 - categorical_accuracy: 0.9156 - val_loss: 0.1328 - val_categorical_accuracy: 0.9556\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.2077 - categorical_accuracy: 0.9111 - val_loss: 0.0719 - val_categorical_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1344 - categorical_accuracy: 0.9600 - val_loss: 0.0592 - val_categorical_accuracy: 0.9778\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1231 - categorical_accuracy: 0.9556 - val_loss: 0.0630 - val_categorical_accuracy: 0.9778\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.4675 - categorical_accuracy: 0.8533 - val_loss: 0.1387 - val_categorical_accuracy: 0.9778\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.2981 - categorical_accuracy: 0.8800 - val_loss: 0.1243 - val_categorical_accuracy: 0.9333\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.2077 - categorical_accuracy: 0.9244 - val_loss: 0.1069 - val_categorical_accuracy: 0.9778\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1483 - categorical_accuracy: 0.9333 - val_loss: 0.0985 - val_categorical_accuracy: 0.9778\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.1245 - categorical_accuracy: 0.9467 - val_loss: 0.0557 - val_categorical_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.2241 - categorical_accuracy: 0.9111 - val_loss: 0.1709 - val_categorical_accuracy: 0.9778\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.2419 - categorical_accuracy: 0.8978 - val_loss: 0.1096 - val_categorical_accuracy: 0.9778\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1861 - categorical_accuracy: 0.9511 - val_loss: 0.0454 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1041 - categorical_accuracy: 0.9600 - val_loss: 0.0551 - val_categorical_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.1024 - categorical_accuracy: 0.9689 - val_loss: 0.2685 - val_categorical_accuracy: 0.9111\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.1340 - categorical_accuracy: 0.9644 - val_loss: 0.1468 - val_categorical_accuracy: 0.9556\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0880 - categorical_accuracy: 0.9778 - val_loss: 0.1139 - val_categorical_accuracy: 0.9778\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0803 - categorical_accuracy: 0.9733 - val_loss: 0.1024 - val_categorical_accuracy: 0.9778\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1263 - categorical_accuracy: 0.9644 - val_loss: 0.1284 - val_categorical_accuracy: 0.9556\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0393 - categorical_accuracy: 0.9867 - val_loss: 0.1294 - val_categorical_accuracy: 0.9556\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0720 - categorical_accuracy: 0.9822 - val_loss: 0.0918 - val_categorical_accuracy: 0.9556\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0664 - categorical_accuracy: 0.9689 - val_loss: 0.1169 - val_categorical_accuracy: 0.9778\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0432 - categorical_accuracy: 0.9778 - val_loss: 0.0709 - val_categorical_accuracy: 0.9778\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0384 - categorical_accuracy: 0.9822 - val_loss: 0.0466 - val_categorical_accuracy: 0.9778\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0365 - categorical_accuracy: 0.9822 - val_loss: 0.0502 - val_categorical_accuracy: 0.9778\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0208 - categorical_accuracy: 0.9956 - val_loss: 0.0540 - val_categorical_accuracy: 0.9778\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0161 - categorical_accuracy: 0.9956 - val_loss: 0.0617 - val_categorical_accuracy: 0.9556\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0164 - categorical_accuracy: 0.9956 - val_loss: 0.0527 - val_categorical_accuracy: 0.9778\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0237 - categorical_accuracy: 0.9911 - val_loss: 0.0384 - val_categorical_accuracy: 0.9778\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.0489 - val_categorical_accuracy: 0.9778\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0110 - categorical_accuracy: 0.9956 - val_loss: 0.0463 - val_categorical_accuracy: 0.9778\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0158 - categorical_accuracy: 0.9956 - val_loss: 0.0477 - val_categorical_accuracy: 0.9778\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 0.0697 - val_categorical_accuracy: 0.9556\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0061 - categorical_accuracy: 1.0000 - val_loss: 0.0738 - val_categorical_accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "AttnLSTM.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "history=AttnLSTM.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a025a2c2-36f5-4d07-bde9-be375b10e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train loss','validation loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a9473d-b07c-44e2-b81f-7f22ef6afc54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model map\n",
    "models = {\n",
    "    'LSTM': lstm, \n",
    "    'LSTM_Attention_128HUs': AttnLSTM, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5067e22d-9a1e-43b4-8450-53b08571a1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    save_dir = os.path.join(os.getcwd(), f\"{model_name}.h5\")\n",
    "    model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aab8f61-1328-41b4-bcba-134c084cf1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run model rebuild before doing this\n",
    "for model_name, model in models.items():\n",
    "    load_dir = os.path.join(os.getcwd(), f\"{model_name}.h5\")\n",
    "    model.load_weights(load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f338317-47f2-49d5-a29b-733e4b2d6c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09680228 0.36830708 0.23004763 0.04330819 0.08225318 0.1792816 ]\n",
      " [0.02671763 0.14656319 0.31110394 0.07101297 0.33260918 0.11199304]\n",
      " [0.12407787 0.42615202 0.18430935 0.03517941 0.06133402 0.16894734]\n",
      " [0.00261564 0.01638659 0.1653441  0.05585712 0.7383121  0.02148429]\n",
      " [0.04799256 0.37404764 0.21941195 0.03960899 0.10838832 0.21055053]\n",
      " [0.03971279 0.22678661 0.29205638 0.06013535 0.23178507 0.14952387]\n",
      " [0.06666918 0.33058214 0.2614292  0.04731702 0.11983904 0.17416336]\n",
      " [0.38085482 0.44051698 0.0617003  0.01826127 0.01093963 0.08772694]\n",
      " [0.21565272 0.5000915  0.09781791 0.02570216 0.02744437 0.13329129]\n",
      " [0.00273028 0.01831035 0.17036621 0.05637144 0.7288669  0.02335488]\n",
      " [0.1881086  0.5102273  0.09941708 0.02633707 0.02965317 0.14625676]\n",
      " [0.45041248 0.38454753 0.06313396 0.01852229 0.00996694 0.07341684]\n",
      " [0.21620387 0.5030171  0.09664332 0.02370986 0.0253465  0.13507931]\n",
      " [0.18899287 0.5160339  0.10036532 0.02417227 0.02816166 0.14227398]\n",
      " [0.04763092 0.2934625  0.26429528 0.05121174 0.16898935 0.1744102 ]\n",
      " [0.2872711  0.47970507 0.07927088 0.02202491 0.01800166 0.1137263 ]\n",
      " [0.10855766 0.48541495 0.14358912 0.0282966  0.05140043 0.18274133]\n",
      " [0.00889738 0.06469237 0.2689189  0.07460945 0.51595587 0.06692593]\n",
      " [0.00258217 0.01548101 0.16363879 0.05624655 0.74132705 0.02072434]\n",
      " [0.36352494 0.4723063  0.05276276 0.01430186 0.00982041 0.08728361]\n",
      " [0.3540311  0.45019984 0.06743591 0.01871985 0.01291444 0.09669887]\n",
      " [0.15930465 0.55664974 0.08395471 0.02261456 0.0254146  0.15206176]\n",
      " [0.22137079 0.48755783 0.09996707 0.02743362 0.02652595 0.13714479]\n",
      " [0.04256935 0.30275813 0.25433883 0.0493397  0.16787955 0.18311442]\n",
      " [0.24749759 0.5294051  0.06914625 0.01977336 0.0170127  0.11716495]\n",
      " [0.21932925 0.5185875  0.08436694 0.02227007 0.02198427 0.13346198]\n",
      " [0.2692826  0.47605452 0.08722175 0.02531258 0.01998232 0.12214623]\n",
      " [0.23328632 0.53263265 0.07452013 0.01926529 0.01985911 0.12043646]\n",
      " [0.1638828  0.51972294 0.1070649  0.02429868 0.03311419 0.15191643]\n",
      " [0.07923    0.36483428 0.23604046 0.04190366 0.09349439 0.18449728]]\n",
      "[[7.90412047e-14 2.94607248e-13 1.08265504e-05 9.99987364e-01\n",
      "  1.80935854e-06 6.35740375e-14]\n",
      " [6.25053431e-08 1.32542773e-04 9.91639853e-01 1.68716814e-03\n",
      "  6.53988402e-03 4.09516247e-07]\n",
      " [3.28179866e-14 1.59980631e-13 1.01361111e-05 9.99987125e-01\n",
      "  2.76766968e-06 6.79522898e-14]\n",
      " [2.06471593e-17 2.10620583e-13 4.53361849e-07 6.87867384e-07\n",
      "  9.99998808e-01 7.84029471e-13]\n",
      " [2.38693974e-05 1.48589332e-02 9.65508461e-01 1.89062338e-02\n",
      "  6.92587986e-04 9.89484215e-06]\n",
      " [3.19841661e-07 3.65214451e-04 9.98936951e-01 5.10750047e-04\n",
      "  1.86601072e-04 7.28551370e-08]\n",
      " [2.82884800e-13 1.97084384e-12 6.55087788e-05 9.99928594e-01\n",
      "  5.88347257e-06 3.69146987e-13]\n",
      " [2.12146074e-06 9.99911666e-01 7.98006877e-05 4.41690599e-06\n",
      "  5.70135383e-10 2.04427693e-06]\n",
      " [2.22064340e-08 3.68604262e-04 1.52044464e-07 2.14152394e-07\n",
      "  6.05558057e-08 9.99630928e-01]\n",
      " [1.11884756e-17 1.33993104e-13 3.26788097e-07 3.74511131e-07\n",
      "  9.99999285e-01 6.60264703e-13]\n",
      " [4.90638463e-09 5.30726720e-05 2.00375439e-07 7.29570075e-08\n",
      "  1.32364192e-07 9.99946475e-01]\n",
      " [2.09621726e-06 4.47749298e-05 9.99227166e-01 6.62254577e-04\n",
      "  6.21514337e-05 1.60285379e-06]\n",
      " [6.13614247e-07 1.34347077e-03 1.35594710e-05 4.91378705e-06\n",
      "  7.68627615e-06 9.98629808e-01]\n",
      " [1.43243951e-05 9.87709641e-01 1.22639490e-02 1.20005270e-05\n",
      "  3.92563093e-09 1.67703604e-07]\n",
      " [1.38781402e-07 1.50728796e-04 9.96826828e-01 2.03510956e-03\n",
      "  9.87039180e-04 1.35935494e-07]\n",
      " [7.38181188e-05 9.89819467e-01 1.00958264e-02 9.64531228e-06\n",
      "  9.36789935e-09 1.20646848e-06]\n",
      " [9.99999404e-01 6.49592835e-07 4.53943798e-08 1.14268806e-09\n",
      "  2.36608456e-14 4.01667692e-11]\n",
      " [7.47457922e-14 1.09474780e-13 4.96596726e-07 9.99992490e-01\n",
      "  6.98144095e-06 5.44376081e-14]\n",
      " [4.37897770e-17 4.44948982e-13 7.48760328e-07 1.17248464e-06\n",
      "  9.99998093e-01 1.00971672e-12]\n",
      " [1.00000000e+00 1.18158026e-08 4.54647431e-09 1.89103819e-13\n",
      "  4.53255767e-18 3.99342729e-14]\n",
      " [1.00000000e+00 8.16524348e-10 7.08924100e-11 1.63206382e-15\n",
      "  2.83659542e-19 2.86470134e-14]\n",
      " [1.70628862e-08 8.49654270e-07 9.95951414e-01 3.35012656e-03\n",
      "  6.97559561e-04 2.63917030e-08]\n",
      " [5.61254987e-10 2.25509757e-05 2.44578793e-08 7.73988162e-09\n",
      "  1.14890950e-08 9.99977469e-01]\n",
      " [9.99999762e-01 2.38432165e-07 5.70823611e-09 1.67537165e-11\n",
      "  1.29958232e-15 1.32563136e-11]\n",
      " [2.53613803e-06 4.07331769e-04 9.97811258e-01 1.75149448e-03\n",
      "  2.72816033e-05 8.88730654e-08]\n",
      " [1.00000000e+00 5.85290998e-08 3.11469767e-10 2.27068222e-14\n",
      "  7.15420372e-17 7.44023870e-11]\n",
      " [2.91774906e-08 8.36052932e-05 2.74509716e-06 4.29756909e-07\n",
      "  2.32090997e-06 9.99910831e-01]\n",
      " [7.25679216e-04 9.91558194e-01 7.29575893e-03 1.40290049e-05\n",
      "  6.28167072e-07 4.05659608e-04]\n",
      " [4.47358445e-07 4.58154222e-03 2.02192223e-06 1.98433190e-06\n",
      "  4.11306843e-07 9.95413601e-01]\n",
      " [4.03416043e-13 4.97784106e-12 1.84041099e-04 9.99811947e-01\n",
      "  4.03174363e-06 6.32183433e-13]]\n"
     ]
    }
   ],
   "source": [
    "for model in models.values():\n",
    "    res = model.predict(X_test, verbose=0)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "335c7db9-b504-4e53-9a2e-2007c286d8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_results = {}\n",
    "eval_results['confusion matrix'] = None\n",
    "eval_results['accuracy'] = None\n",
    "eval_results['precision'] = None\n",
    "eval_results['recall'] = None\n",
    "eval_results['f1 score'] = None\n",
    "\n",
    "confusion_matrices = {}\n",
    "classification_accuracies = {}   \n",
    "precisions = {}\n",
    "recalls = {}\n",
    "f1_scores = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad7be8e8-c74d-4f3d-826e-b4d730b72987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM confusion matrix: \n",
      "[[[24  1]\n",
      "  [ 5  0]]\n",
      "\n",
      " [[ 7 19]\n",
      "  [ 0  4]]\n",
      "\n",
      " [[23  0]\n",
      "  [ 6  1]]\n",
      "\n",
      " [[25  0]\n",
      "  [ 5  0]]\n",
      "\n",
      " [[25  2]\n",
      "  [ 0  3]]\n",
      "\n",
      " [[24  0]\n",
      "  [ 6  0]]]\n",
      "LSTM_Attention_128HUs confusion matrix: \n",
      "[[[25  0]\n",
      "  [ 0  5]]\n",
      "\n",
      " [[26  0]\n",
      "  [ 0  4]]\n",
      "\n",
      " [[23  0]\n",
      "  [ 0  7]]\n",
      "\n",
      " [[25  0]\n",
      "  [ 0  5]]\n",
      "\n",
      " [[27  0]\n",
      "  [ 0  3]]\n",
      "\n",
      " [[24  0]\n",
      "  [ 0  6]]]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_matrices[model_name] = multilabel_confusion_matrix(ytrue, yhat)\n",
    "    print(f\"{model_name} confusion matrix: {os.linesep}{confusion_matrices[model_name]}\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['confusion matrix'] = confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d88643a-3914-4f7d-bb5d-3f4108eb58ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM classification accuracy = 26.667%\n",
      "LSTM_Attention_128HUs classification accuracy = 100.0%\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Model accuracy\n",
    "    classification_accuracies[model_name] = accuracy_score(ytrue, yhat)    \n",
    "    print(f\"{model_name} classification accuracy = {round(classification_accuracies[model_name]*100,3)}%\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['accuracy'] = classification_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6160dfb5-c331-4886-8b50-b76f90461713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM weighted average precision = 0.317\n",
      "LSTM weighted average recall = 0.267\n",
      "LSTM weighted average f1-score = 0.173\n",
      "\n",
      "LSTM_Attention_128HUs weighted average precision = 1.0\n",
      "LSTM_Attention_128HUs weighted average recall = 1.0\n",
      "LSTM_Attention_128HUs weighted average f1-score = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Precision, recall, and f1 score\n",
    "    report = classification_report(ytrue, yhat, target_names=actions, output_dict=True)\n",
    "    \n",
    "    precisions[model_name] = report['weighted avg']['precision']\n",
    "    recalls[model_name] = report['weighted avg']['recall']\n",
    "    f1_scores[model_name] = report['weighted avg']['f1-score'] \n",
    "   \n",
    "    print(f\"{model_name} weighted average precision = {round(precisions[model_name],3)}\")\n",
    "    print(f\"{model_name} weighted average recall = {round(recalls[model_name],3)}\")\n",
    "    print(f\"{model_name} weighted average f1-score = {round(f1_scores[model_name],3)}\\n\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['precision'] = precisions\n",
    "eval_results['recall'] = recalls\n",
    "eval_results['f1 score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee927a6-0a78-460a-9140-731bde144b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AttnLSTM\n",
    "model_name = 'AttnLSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6518d6b9-d0b4-4cf9-aad7-b35adc406062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    \"\"\"\n",
    "    Computes 3D joint angle inferred by 3 keypoints and their relative positions to one another\n",
    "    \n",
    "    \"\"\"\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f4302c0-1648-4fde-bad2-114dbd806739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_coordinates(landmarks, mp_pose, side, joint):\n",
    "    \"\"\"\n",
    "    Retrieves x and y coordinates of a particular keypoint from the pose estimation model\n",
    "         \n",
    "     Args:\n",
    "         landmarks: processed keypoints from the pose estimation model\n",
    "         mp_pose: Mediapipe pose estimation model\n",
    "         side: 'left' or 'right'. Denotes the side of the body of the landmark of interest.\n",
    "         joint: 'shoulder', 'elbow', 'wrist', 'hip', 'knee', or 'ankle'. Denotes which body joint is associated with the landmark of interest.\n",
    "    \n",
    "    \"\"\"\n",
    "    coord = getattr(mp_pose.PoseLandmark,side.upper()+\"_\"+joint.upper())\n",
    "    x_coord_val = landmarks[coord.value].x\n",
    "    y_coord_val = landmarks[coord.value].y\n",
    "    return [x_coord_val, y_coord_val]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7020ab-fd0e-4b29-9897-851e12793407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_joint_angle(image, angle, joint):\n",
    "    \"\"\"\n",
    "    Displays the joint angle value near the joint within the image frame\n",
    "    \n",
    "    \"\"\"\n",
    "    cv2.putText(image, str(int(angle)), \n",
    "                   tuple(np.multiply(joint, [640, 480]).astype(int)), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd1d3fa8-5ddf-46cd-b778-b3003015619b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_reps(image, current_action, landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Counts repetitions of each exercise. Global count and stage (i.e., state) variables are updated within this function.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    global curl_counter, press_counter, squat_counter, pushup_counter, leg_raise_counter, jumping_jacks_counter, curl_stage, press_stage, squat_stage, pushup_stage, leg_raise_stage, jumping_jacks_stage\n",
    "    \n",
    "    if current_action == 'curl':\n",
    "        # Get coords\n",
    "        shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        \n",
    "        # calculate elbow angle\n",
    "        angle = calculate_angle(shoulder, elbow, wrist)\n",
    "        \n",
    "        # curl counter logic\n",
    "        if angle < 30:\n",
    "            curl_stage = \"up\" \n",
    "        if angle > 140 and curl_stage =='up':\n",
    "            curl_stage=\"down\"  \n",
    "            curl_counter +=1\n",
    "        press_stage = None\n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angle\n",
    "        viz_joint_angle(image, angle, elbow)\n",
    "        \n",
    "    elif current_action == 'press':\n",
    "        \n",
    "        # Get coords\n",
    "        shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "\n",
    "        # Calculate elbow angle\n",
    "        elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "        \n",
    "        # Compute distances between joints\n",
    "        shoulder2elbow_dist = abs(math.dist(shoulder,elbow))\n",
    "        shoulder2wrist_dist = abs(math.dist(shoulder,wrist))\n",
    "        \n",
    "        # Press counter logic\n",
    "        if (elbow_angle > 130) and (shoulder2elbow_dist < shoulder2wrist_dist):\n",
    "            press_stage = \"up\"\n",
    "        if (elbow_angle < 50) and (shoulder2elbow_dist > shoulder2wrist_dist) and (press_stage =='up'):\n",
    "            press_stage='down'\n",
    "            press_counter += 1\n",
    "        curl_stage = None\n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angle\n",
    "        viz_joint_angle(image, elbow_angle, elbow)\n",
    "        \n",
    "    elif current_action == 'squat':\n",
    "        # Get coords\n",
    "        # left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "        # right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "        \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        \n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        \n",
    "        # Squat counter logic\n",
    "        thr = 165\n",
    "        if (left_knee_angle < thr) and (right_knee_angle < thr) and (left_hip_angle < thr) and (right_hip_angle < thr):\n",
    "            squat_stage = \"down\"\n",
    "        if (left_knee_angle > thr) and (right_knee_angle > thr) and (left_hip_angle > thr) and (right_hip_angle > thr) and (squat_stage =='down'):\n",
    "            squat_stage='up'\n",
    "            squat_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angles\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "        viz_joint_angle(image, left_hip_angle, left_hip)\n",
    "    \n",
    "    elif current_action == 'pushup':\n",
    "         # Get coordinates\n",
    "         # left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        left_wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "        # right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_elbow = get_coordinates(landmarks, mp_pose, 'right', 'elbow')\n",
    "        right_wrist = get_coordinates(landmarks, mp_pose, 'right', 'wrist')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "    \n",
    "        # Calculate elbow angles\n",
    "        left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "    \n",
    "        # Push-up counter logic\n",
    "        thr_pushup = 170  # Adjust threshold as needed\n",
    "        if (left_elbow_angle < thr_pushup) and (right_elbow_angle < thr_pushup) and (left_hip_angle > 165) and (right_hip_angle > 165):\n",
    "            pushup_stage = \"down\"\n",
    "        if (left_elbow_angle > thr_pushup) and (right_elbow_angle > thr_pushup) and (pushup_stage == 'down') and (left_hip_angle > 165) and (right_hip_angle > 165):\n",
    "            pushup_stage = 'up'\n",
    "            pushup_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "        \n",
    "        \n",
    "        # Visualize joint angles\n",
    "        viz_joint_angle(image, left_elbow_angle, left_elbow)\n",
    "        viz_joint_angle(image, right_elbow_angle, right_elbow) \n",
    "        viz_joint_angle(image, left_hip_angle, left_hip)\n",
    "        viz_joint_angle(image, right_hip_angle, right_hip)\n",
    "        \n",
    "    elif current_action == 'leg_raise':\n",
    "         # Get coordinates\n",
    "         # Left side\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "    \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    \n",
    "        # Leg raise counter logic\n",
    "        thr_leg_raise = 160  # Adjust threshold as needed\n",
    "        if left_knee_angle > thr_leg_raise:\n",
    "            leg_raise_stage = \"up\"\n",
    "        if left_knee_angle < thr_leg_raise and leg_raise_stage == 'up':\n",
    "            leg_raise_stage = 'down'\n",
    "            leg_raise_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "        \n",
    "        # Visualize joint angle\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "    \n",
    "    elif current_action == 'jumping_jacks':\n",
    "         # Get coordinates\n",
    "         # Left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        left_wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "    \n",
    "        # Right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_elbow = get_coordinates(landmarks, mp_pose, 'right', 'elbow')\n",
    "        right_wrist = get_coordinates(landmarks, mp_pose, 'right', 'wrist')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "    \n",
    "        # Calculate elbow angles\n",
    "        left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    \n",
    "        # Jumping jacks counter logic\n",
    "        thr_jumping_jacks = 160  # Adjust threshold as needed\n",
    "        if (left_elbow_angle < thr_jumping_jacks) and (right_elbow_angle < thr_jumping_jacks) and (left_knee_angle > 165) and (right_knee_angle > 165):\n",
    "            jumping_jacks_stage = \"up\"\n",
    "        if (left_elbow_angle > thr_jumping_jacks) and (right_elbow_angle > thr_jumping_jacks) and (jumping_jacks_stage == 'up'):\n",
    "            jumping_jacks_stage = 'down'\n",
    "            jumping_jacks_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        \n",
    "        # Visualize joint angles\n",
    "        viz_joint_angle(image, left_elbow_angle, left_elbow)\n",
    "        viz_joint_angle(image, right_elbow_angle, right_elbow)\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "        viz_joint_angle(image, right_knee_angle, right_knee)\n",
    "\n",
    "    else:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7475713a-aac6-4d82-ba56-f4e041f7f841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    \"\"\"\n",
    "    This function displays the model prediction probability distribution over the set of exercise classes\n",
    "    as a horizontal bar graph\n",
    "    \n",
    "    \"\"\"\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):        \n",
    "        cv2.rectangle(output_frame, (0,120+num*40), (int(prob*100), 160+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 150+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebee4b05-0cf8-4a60-bab9-2d756024a4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is: C:\\Users\\ACER\\tensor\\project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(f\"The current working directory is: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5440179f-f321-403f-90c7-3223e24d4249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "predictions = []\n",
    "res = []\n",
    "threshold = 0.5 # minimum confidence to classify as an action/exercise\n",
    "current_action = ''\n",
    "\n",
    "# Rep counter logic variables\n",
    "curl_counter = 0\n",
    "press_counter = 0\n",
    "squat_counter = 0\n",
    "pushup_counter = 0\n",
    "leg_raise_counter = 0\n",
    "jumping_jacks_counter = 0\n",
    "curl_stage = None\n",
    "press_stage = None\n",
    "squat_stage = None\n",
    "pushup_stage = None\n",
    "leg_raise_stage = None\n",
    "jumping_jacks_stage = None\n",
    "\n",
    "# Camera object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Video writer object that saves a video of the real time test\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G') # video compression format\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # webcam video frame height\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # webcam video frame width\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # webcam video fram rate \n",
    "\n",
    "video_name = os.path.join(os.getcwd(),f\"{model_name}_real_time_test.avi\")\n",
    "out = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*\"MJPG\"), FPS, (WIDTH,HEIGHT))\n",
    "\n",
    "# Set mediapipe model \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detection\n",
    "        image, results = mediapipe_detection(frame, pose)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)        \n",
    "        sequence.append(keypoints)      \n",
    "        sequence = sequence[-sequence_length:]\n",
    "              \n",
    "        if len(sequence) == sequence_length:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]           \n",
    "            predictions.append(np.argmax(res))\n",
    "            current_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "            \n",
    "        #3. Viz logic\n",
    "            # Erase current action variable if no probability is above threshold\n",
    "            if confidence < threshold:\n",
    "                current_action = ''\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "            # Count reps\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                count_reps(\n",
    "                    image, current_action, landmarks, mp_pose)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Display graphical information\n",
    "            #cv2.rectangle(image, (0,0), (640, 80), colors[np.argmax(res)], -1)\n",
    "            cv2.putText(image, 'curl ' + str(curl_counter), (3,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 117, 16), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'press ' + str(press_counter), (240,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (117, 245, 16), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'squat ' + str(squat_counter), (490,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (16, 117, 245), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'pushup ' + str(pushup_counter), (3,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (117, 16, 245), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'leg_raise ' + str(leg_raise_counter), (220,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 16, 117), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'jumping_jacks ' + str(jumping_jacks_counter), (490,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (16, 245, 117), 2, cv2.LINE_AA)\n",
    "         \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Write to video file\n",
    "        if ret == True:\n",
    "            out.write(image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "785327ce-3016-482e-b33b-aa8a1c0cfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857af89b-e8c0-4c6a-abb3-56456980d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946125eb-2f5b-4def-8dec-57540047e08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import subprocess\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def set_background_image(window, image_path):\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Convert the image to Tkinter PhotoImage\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    \n",
    "    # Create a label with the image\n",
    "    bg_label = tk.Label(window, image=photo)\n",
    "    bg_label.place(relwidth=1, relheight=1)  # Cover the entire window\n",
    "    \n",
    "    # Keep a reference to the image to avoid garbage collection\n",
    "    bg_label.image = photo\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"fitness pose estimation\")\n",
    "\n",
    "window_width = 600\n",
    "window_height = 400\n",
    "root.geometry(f\"{window_width}x{window_height}\")\n",
    "\n",
    "min_width = 200\n",
    "min_height = 150\n",
    "root.minsize(min_width, min_height)\n",
    "\n",
    "# Set the maximum window size\n",
    "max_width = 600\n",
    "max_height = 450\n",
    "root.maxsize(max_width, max_height)\n",
    "# Set the background image\n",
    "image_path = r\"C:\\Users\\ACER\\tensor\\project\\image.jpg\"\n",
    "set_background_image(root, image_path)\n",
    "\n",
    "def start_button_clicked():\n",
    "    # Open the next Python file using subprocess\n",
    "    subprocess.run([\"python\", \"C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.py\"])\n",
    "start_button = tk.Button(root, text=\"Start-WorkOut\", command=start_button_clicked,font=('Georgia',13,\"bold\"))\n",
    "start_button.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "\n",
    "# Add other widgets or functionality as needed\n",
    "text_label = tk.Label(root, text=\"Fitness At Home \\nUsing Pose Estimation\",font=('Georgia',25,\"bold\"))\n",
    "text_label.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569de7e-4a3f-4472-ba83-54628475626b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanpose",
   "language": "python",
   "name": "humanpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
