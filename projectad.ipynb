{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9861e009-a76a-4d15-9544-7043f5280a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install  tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4d06a4-2495-4c90-a78a-cd7fe31a41e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\acer\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73b3b69-8a52-4a3e-9d30-50ea44c5e0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c63efcc-cb79-4cec-b257-32e61b78a109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.10.9)\n",
      "Requirement already satisfied: absl-py in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acer\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install  mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f6526e-4891-4c2a-a7b7-fba87543be09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888e4c54-c093-41be-9a97-428e6e054fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.layers import (LSTM, Dense, Concatenate, Attention, Dropout, Softmax,\n",
    "                                     Input, Flatten, Activation, Bidirectional, Permute, multiply, \n",
    "                                     ConvLSTM2D, MaxPooling3D, TimeDistributed, Conv2D, MaxPooling2D)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# disable some of the tf/keras training warnings \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "tf.autograph.set_verbosity(1)\n",
    "\n",
    "# suppress untraced functions warning\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa6175f-be08-4403-a20c-416bab140899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-trained pose estimation model from Google Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Supported Mediapipe visualization tools\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315e1e36-1d70-44ba-adc1-7852409350aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"\n",
    "    This function detects human pose estimation keypoints from webcam footage\n",
    "    \n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37a000f-2506-4fcc-91fe-ab2445e23d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    \"\"\"\n",
    "    This function draws keypoints and landmarks detected by the human pose estimation model\n",
    "    \n",
    "    \"\"\"\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d117d63c-ce5e-4c13-afed-57212572ad40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # camera object\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # webcam video frame height\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # webcam video frame width\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # webcam video fram rate \n",
    "\n",
    "# Set and test mediapipe model using webcam\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "      \n",
    "        # Make detection\n",
    "        image, results = mediapipe_detection(frame, pose)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render detections\n",
    "        draw_landmarks(image, results)               \n",
    "        \n",
    "        # Display frame on screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Exit / break out logic\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486ca325-b4ad-4d66-9b06-0ac5478c0d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recollect and organize keypoints from the test\n",
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcaca19f-da38-4f92-86b5-93d4cdfdbf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 33 landmarks with 4 values (x, y, z, visibility)\n",
    "num_landmarks = len(landmarks)\n",
    "num_values = len(test)\n",
    "num_input_values = num_landmarks*num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687753d2-e944-4d1a-bf32-ee7e7c5fa38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an example of what we would use as an input into our AI models\n",
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b913d8df-51a8-4ebf-a97e-b5fa1133864a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \"\"\"\n",
    "    Processes and organizes the keypoints detected from the pose estimation model \n",
    "    to be used as inputs for the exercise decoder models\n",
    "    \n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716a5fa0-11fc-45ed-8f4f-fbe59b36814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\tensor\\project\\data\n"
     ]
    }
   ],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join(os. getcwd(),'data') \n",
    "print(DATA_PATH)\n",
    "\n",
    "# make directory if it does not exist yet\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# Actions/exercises that we try to detect\n",
    "actions = np.array(['curl', 'press', 'squat', 'pushup', 'leg_raise', 'jumping_jacks'])\n",
    "num_classes = len(actions)\n",
    "\n",
    "# How many videos worth of data\n",
    "no_sequences = 50\n",
    "\n",
    "# Videos are going to be this many frames in length\n",
    "sequence_length = FPS*1\n",
    "\n",
    "# Folder start\n",
    "# Change this to collect more data and not lose previously collected data\n",
    "start_folder = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "193e0577-83d3-4634-b40e-f7a66c735cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build folder paths\n",
    "for action in actions:     \n",
    "    for sequence in range(start_folder,no_sequences+start_folder):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))  \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b5c22e-4562-4ab9-921a-9871e0e7c838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colors associated with each exercise (e.g., curls are denoted by blue, squats are denoted by orange, etc.)\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245), (117,16,245), (245,16,117), (16,245,117)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0597ada9-155a-4f4a-bb51-4d53d417ef0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect Training Data\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    # Loop through actions\n",
    "    for idx, action in enumerate(actions):\n",
    "        # Loop through sequences (i.e., videos)\n",
    "        for sequence in range(start_folder, start_folder+no_sequences):\n",
    "            # Loop through video length (i.e, sequence length)\n",
    "            for frame_num in range(sequence_length):\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                # Make detection\n",
    "                image, results = mediapipe_detection(frame, pose)\n",
    "\n",
    "                # Extract landmarks\n",
    "                try:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Render detections\n",
    "                draw_landmarks(image, results) \n",
    "\n",
    "                # Apply visualization logic\n",
    "                if frame_num == 0: # If first frame in sequence, print that you're starting a new data collection and wait 500 ms\n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 8, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, colors[idx], 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(500)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 8, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting {} Video # {}'.format(action, sequence), (15,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, colors[idx], 4, cv2.LINE_AA)\n",
    "                    \n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # Export keypoints (sequence + pose landmarks)\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60c6dbd4-fee4-477c-bfcf-06955a672674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd4c6f23-e802-450d-affe-48998d025a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f2a8b2a-d7a1-478a-a561-fca453129fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4376568e-72cc-41a1-a736-68623bfe142c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and organize recorded training data\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):         \n",
    "            # LSTM input data\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)  \n",
    "            \n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b0ec449-8388-41ed-93b9-b560a032d19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 30, 132) (300, 6)\n"
     ]
    }
   ],
   "source": [
    "# Make sure first dimensions of arrays match\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dde97c00-8f6e-4ae5-8252-3453f0be2329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 30, 132) (270, 6)\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation, and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=15/90, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2114bb0-6056-4e4f-a0af-8bb95cd5d5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks to be used during neural network training \n",
    "#es_callback = EarlyStopping(monitor='val_loss', min_delta=5e-4, patience=10, verbose=0, mode='min')\n",
    "#lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=0, mode='min')\n",
    "#chkpt_callback = ModelCheckpoint(filepath=DATA_PATH, monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                               #  save_weights_only=False, mode='min', save_freq=1)\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# some hyperparamters\n",
    "batch_size = 32\n",
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2108a26a-37f7-4e69-a607-9aaefd8a25f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard logging and callbacks\n",
    "NAME = f\"ExerciseRecognition-LSTM-{int(time.time())}\"\n",
    "log_dir = os.path.join(os.getcwd(), 'logs', NAME,'')\n",
    "#tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#callbacks = [tb_callback, es_callback, lr_callback, chkpt_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d27c363-83d8-4516-9b2e-0522a9e1b4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 128)           133632    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 256)           394240    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750150 (2.86 MB)\n",
      "Trainable params: 750150 (2.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(sequence_length, num_input_values)))\n",
    "lstm.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "lstm.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "lstm.add(Dense(128, activation='relu'))\n",
    "lstm.add(Dense(64, activation='relu'))\n",
    "lstm.add(Dense(actions.shape[0], activation='softmax'))\n",
    "print(lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beeca98f-f93e-478d-af63-56f9df53090a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 8s 262ms/step - loss: 39335.0391 - categorical_accuracy: 0.1511 - val_loss: 138628.3438 - val_categorical_accuracy: 0.1556\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 25275.8828 - categorical_accuracy: 0.1689 - val_loss: 408.6750 - val_categorical_accuracy: 0.1556\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 103.8346 - categorical_accuracy: 0.1956 - val_loss: 84.2598 - val_categorical_accuracy: 0.1333\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 182.6530 - categorical_accuracy: 0.1644 - val_loss: 184.5667 - val_categorical_accuracy: 0.2222\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 158.6114 - categorical_accuracy: 0.1422 - val_loss: 249.4622 - val_categorical_accuracy: 0.1556\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 76.6418 - categorical_accuracy: 0.1644 - val_loss: 91.4636 - val_categorical_accuracy: 0.0889\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 39.0557 - categorical_accuracy: 0.1644 - val_loss: 22.9520 - val_categorical_accuracy: 0.2889\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 14.3134 - categorical_accuracy: 0.2000 - val_loss: 9.3150 - val_categorical_accuracy: 0.1556\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 7.3991 - categorical_accuracy: 0.1644 - val_loss: 10.9589 - val_categorical_accuracy: 0.2000\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 6.9431 - categorical_accuracy: 0.1733 - val_loss: 3.5581 - val_categorical_accuracy: 0.1778\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 3.5230 - categorical_accuracy: 0.1911 - val_loss: 2.6094 - val_categorical_accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.5866 - categorical_accuracy: 0.1911 - val_loss: 2.7570 - val_categorical_accuracy: 0.3111\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.5845 - categorical_accuracy: 0.1822 - val_loss: 1.9303 - val_categorical_accuracy: 0.1111\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.9617 - categorical_accuracy: 0.2711 - val_loss: 1.7360 - val_categorical_accuracy: 0.0444\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.8376 - categorical_accuracy: 0.0711 - val_loss: 1.7478 - val_categorical_accuracy: 0.1556\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.7877 - categorical_accuracy: 0.1822 - val_loss: 1.7202 - val_categorical_accuracy: 0.1556\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.8611 - categorical_accuracy: 0.3111 - val_loss: 1.7216 - val_categorical_accuracy: 0.1778\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.7219 - categorical_accuracy: 0.1333 - val_loss: 1.6609 - val_categorical_accuracy: 0.2889\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.8389 - categorical_accuracy: 0.2667 - val_loss: 1.6772 - val_categorical_accuracy: 0.3556\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.6799 - categorical_accuracy: 0.2400 - val_loss: 1.6935 - val_categorical_accuracy: 0.2667\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7384 - categorical_accuracy: 0.2667 - val_loss: 1.8089 - val_categorical_accuracy: 0.2000\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7137 - categorical_accuracy: 0.2000 - val_loss: 1.7606 - val_categorical_accuracy: 0.3333\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.8427 - categorical_accuracy: 0.2711 - val_loss: 1.6086 - val_categorical_accuracy: 0.2667\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7582 - categorical_accuracy: 0.2933 - val_loss: 1.6255 - val_categorical_accuracy: 0.1556\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.6163 - categorical_accuracy: 0.2400 - val_loss: 1.5280 - val_categorical_accuracy: 0.3333\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.5419 - categorical_accuracy: 0.3111 - val_loss: 1.5434 - val_categorical_accuracy: 0.3556\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5541 - categorical_accuracy: 0.3289 - val_loss: 1.5414 - val_categorical_accuracy: 0.2889\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.5700 - categorical_accuracy: 0.3200 - val_loss: 1.6029 - val_categorical_accuracy: 0.2667\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.5406 - categorical_accuracy: 0.3022 - val_loss: 1.5129 - val_categorical_accuracy: 0.3111\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.5025 - categorical_accuracy: 0.2978 - val_loss: 1.5100 - val_categorical_accuracy: 0.2667\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.4951 - categorical_accuracy: 0.3022 - val_loss: 1.6477 - val_categorical_accuracy: 0.3333\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7958 - categorical_accuracy: 0.3600 - val_loss: 1.7002 - val_categorical_accuracy: 0.1778\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.1671 - categorical_accuracy: 0.1956 - val_loss: 1.6664 - val_categorical_accuracy: 0.2667\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.0307 - categorical_accuracy: 0.2267 - val_loss: 1.7084 - val_categorical_accuracy: 0.2444\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7427 - categorical_accuracy: 0.2622 - val_loss: 1.5914 - val_categorical_accuracy: 0.2667\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.6205 - categorical_accuracy: 0.3111 - val_loss: 1.6187 - val_categorical_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.6237 - categorical_accuracy: 0.3333 - val_loss: 1.6198 - val_categorical_accuracy: 0.2889\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.6164 - categorical_accuracy: 0.2667 - val_loss: 1.5647 - val_categorical_accuracy: 0.2667\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.5775 - categorical_accuracy: 0.2578 - val_loss: 1.5628 - val_categorical_accuracy: 0.2222\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.5176 - categorical_accuracy: 0.2844 - val_loss: 1.5574 - val_categorical_accuracy: 0.2667\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.5723 - categorical_accuracy: 0.2933 - val_loss: 1.4852 - val_categorical_accuracy: 0.2889\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.6290 - categorical_accuracy: 0.2889 - val_loss: 1.4812 - val_categorical_accuracy: 0.3556\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.4970 - categorical_accuracy: 0.2711 - val_loss: 1.5171 - val_categorical_accuracy: 0.3778\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.5288 - categorical_accuracy: 0.3644 - val_loss: 1.4912 - val_categorical_accuracy: 0.2889\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.4519 - categorical_accuracy: 0.3467 - val_loss: 1.4831 - val_categorical_accuracy: 0.2889\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.4796 - categorical_accuracy: 0.3511 - val_loss: 1.4736 - val_categorical_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.4758 - categorical_accuracy: 0.3689 - val_loss: 1.5208 - val_categorical_accuracy: 0.3556\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.5504 - categorical_accuracy: 0.4044 - val_loss: 1.3715 - val_categorical_accuracy: 0.3556\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.3491 - categorical_accuracy: 0.4267 - val_loss: 1.3064 - val_categorical_accuracy: 0.4222\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.3743 - categorical_accuracy: 0.4311 - val_loss: 1.4572 - val_categorical_accuracy: 0.4000\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1377038.5000 - categorical_accuracy: 0.2622 - val_loss: 54929.9492 - val_categorical_accuracy: 0.1333\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 74828.9688 - categorical_accuracy: 0.1467 - val_loss: 8903676.0000 - val_categorical_accuracy: 0.1333\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1373161.6250 - categorical_accuracy: 0.1689 - val_loss: 433.3121 - val_categorical_accuracy: 0.1333\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 266.2517 - categorical_accuracy: 0.1644 - val_loss: 64.8123 - val_categorical_accuracy: 0.1333\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 39.2669 - categorical_accuracy: 0.1600 - val_loss: 27.0105 - val_categorical_accuracy: 0.1333\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 9277.4746 - categorical_accuracy: 0.1822 - val_loss: 5845.0723 - val_categorical_accuracy: 0.1333\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1484434.3750 - categorical_accuracy: 0.1911 - val_loss: 1315648.3750 - val_categorical_accuracy: 0.2222\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1342503.8750 - categorical_accuracy: 0.1644 - val_loss: 29487.3809 - val_categorical_accuracy: 0.1333\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 5176.7095 - categorical_accuracy: 0.1822 - val_loss: 161.8306 - val_categorical_accuracy: 0.2222\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 17.7378 - categorical_accuracy: 0.1556 - val_loss: 1.8051 - val_categorical_accuracy: 0.2222\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.8499 - categorical_accuracy: 0.1556 - val_loss: 1.8016 - val_categorical_accuracy: 0.2222\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.8427 - categorical_accuracy: 0.1556 - val_loss: 1.7983 - val_categorical_accuracy: 0.2222\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.8363 - categorical_accuracy: 0.1556 - val_loss: 1.7960 - val_categorical_accuracy: 0.2222\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.8324 - categorical_accuracy: 0.1556 - val_loss: 1.7950 - val_categorical_accuracy: 0.2222\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.8280 - categorical_accuracy: 0.1511 - val_loss: 1.7936 - val_categorical_accuracy: 0.1556\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.8228 - categorical_accuracy: 0.1733 - val_loss: 1.7919 - val_categorical_accuracy: 0.1556\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.8181 - categorical_accuracy: 0.1733 - val_loss: 1.7904 - val_categorical_accuracy: 0.1556\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.8131 - categorical_accuracy: 0.1733 - val_loss: 1.7893 - val_categorical_accuracy: 0.1556\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.8085 - categorical_accuracy: 0.1733 - val_loss: 1.7888 - val_categorical_accuracy: 0.1556\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.8059 - categorical_accuracy: 0.1733 - val_loss: 1.7884 - val_categorical_accuracy: 0.1556\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.8031 - categorical_accuracy: 0.1733 - val_loss: 1.7874 - val_categorical_accuracy: 0.1556\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.8011 - categorical_accuracy: 0.1733 - val_loss: 1.7871 - val_categorical_accuracy: 0.1556\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.7992 - categorical_accuracy: 0.1733 - val_loss: 1.7863 - val_categorical_accuracy: 0.1556\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7973 - categorical_accuracy: 0.1733 - val_loss: 1.7868 - val_categorical_accuracy: 0.1556\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7968 - categorical_accuracy: 0.1733 - val_loss: 1.7879 - val_categorical_accuracy: 0.1556\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.7955 - categorical_accuracy: 0.1733 - val_loss: 1.7895 - val_categorical_accuracy: 0.1556\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7951 - categorical_accuracy: 0.1733 - val_loss: 1.7908 - val_categorical_accuracy: 0.1556\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.7946 - categorical_accuracy: 0.1733 - val_loss: 1.7908 - val_categorical_accuracy: 0.1556\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.7949 - categorical_accuracy: 0.1733 - val_loss: 1.7905 - val_categorical_accuracy: 0.1556\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7943 - categorical_accuracy: 0.1733 - val_loss: 1.7914 - val_categorical_accuracy: 0.1556\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7942 - categorical_accuracy: 0.1733 - val_loss: 1.7923 - val_categorical_accuracy: 0.1556\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.7945 - categorical_accuracy: 0.1733 - val_loss: 1.7916 - val_categorical_accuracy: 0.1556\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7947 - categorical_accuracy: 0.1733 - val_loss: 1.7918 - val_categorical_accuracy: 0.1556\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7953 - categorical_accuracy: 0.1733 - val_loss: 1.7910 - val_categorical_accuracy: 0.1556\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7939 - categorical_accuracy: 0.1733 - val_loss: 1.7912 - val_categorical_accuracy: 0.1556\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7938 - categorical_accuracy: 0.1733 - val_loss: 1.7922 - val_categorical_accuracy: 0.1556\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7930 - categorical_accuracy: 0.1733 - val_loss: 1.7933 - val_categorical_accuracy: 0.1556\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.7931 - categorical_accuracy: 0.1733 - val_loss: 1.7931 - val_categorical_accuracy: 0.1556\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 1.7933 - categorical_accuracy: 0.1733 - val_loss: 1.7933 - val_categorical_accuracy: 0.1556\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7929 - categorical_accuracy: 0.1733 - val_loss: 1.7929 - val_categorical_accuracy: 0.1556\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7926 - categorical_accuracy: 0.1733 - val_loss: 1.7934 - val_categorical_accuracy: 0.1556\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7923 - categorical_accuracy: 0.1733 - val_loss: 1.7930 - val_categorical_accuracy: 0.1556\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 1.7918 - categorical_accuracy: 0.1733 - val_loss: 1.7933 - val_categorical_accuracy: 0.1556\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7921 - categorical_accuracy: 0.1733 - val_loss: 1.7945 - val_categorical_accuracy: 0.1556\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7917 - categorical_accuracy: 0.1733 - val_loss: 1.7959 - val_categorical_accuracy: 0.1556\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7915 - categorical_accuracy: 0.1733 - val_loss: 1.7974 - val_categorical_accuracy: 0.1556\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7914 - categorical_accuracy: 0.1733 - val_loss: 1.7990 - val_categorical_accuracy: 0.1556\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7914 - categorical_accuracy: 0.1733 - val_loss: 1.8006 - val_categorical_accuracy: 0.1333\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7920 - categorical_accuracy: 0.1689 - val_loss: 1.8021 - val_categorical_accuracy: 0.1333\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7920 - categorical_accuracy: 0.1600 - val_loss: 1.8032 - val_categorical_accuracy: 0.1556\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7915 - categorical_accuracy: 0.1733 - val_loss: 1.8033 - val_categorical_accuracy: 0.1556\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7910 - categorical_accuracy: 0.1733 - val_loss: 1.8016 - val_categorical_accuracy: 0.1556\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7911 - categorical_accuracy: 0.1778 - val_loss: 1.8014 - val_categorical_accuracy: 0.1556\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.7912 - categorical_accuracy: 0.1778 - val_loss: 1.8020 - val_categorical_accuracy: 0.1556\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7913 - categorical_accuracy: 0.1778 - val_loss: 1.8029 - val_categorical_accuracy: 0.1556\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.8039 - val_categorical_accuracy: 0.1556\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7920 - categorical_accuracy: 0.1778 - val_loss: 1.8049 - val_categorical_accuracy: 0.1556\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7927 - categorical_accuracy: 0.1733 - val_loss: 1.8065 - val_categorical_accuracy: 0.1556\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.7928 - categorical_accuracy: 0.1733 - val_loss: 1.8074 - val_categorical_accuracy: 0.1556\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7935 - categorical_accuracy: 0.1733 - val_loss: 1.8078 - val_categorical_accuracy: 0.1556\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7934 - categorical_accuracy: 0.2044 - val_loss: 1.8067 - val_categorical_accuracy: 0.1556\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7927 - categorical_accuracy: 0.1778 - val_loss: 1.8065 - val_categorical_accuracy: 0.1556\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.7924 - categorical_accuracy: 0.1778 - val_loss: 1.8070 - val_categorical_accuracy: 0.1556\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7922 - categorical_accuracy: 0.1556 - val_loss: 1.8076 - val_categorical_accuracy: 0.1556\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7927 - categorical_accuracy: 0.1733 - val_loss: 1.8082 - val_categorical_accuracy: 0.1556\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7923 - categorical_accuracy: 0.1733 - val_loss: 1.8066 - val_categorical_accuracy: 0.1556\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7929 - categorical_accuracy: 0.1733 - val_loss: 1.8032 - val_categorical_accuracy: 0.1556\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7920 - categorical_accuracy: 0.1733 - val_loss: 1.8024 - val_categorical_accuracy: 0.1556\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.7919 - categorical_accuracy: 0.1733 - val_loss: 1.8011 - val_categorical_accuracy: 0.1556\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7921 - categorical_accuracy: 0.1733 - val_loss: 1.8011 - val_categorical_accuracy: 0.1556\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7922 - categorical_accuracy: 0.1733 - val_loss: 1.8018 - val_categorical_accuracy: 0.1556\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7932 - categorical_accuracy: 0.1733 - val_loss: 1.8031 - val_categorical_accuracy: 0.1556\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7926 - categorical_accuracy: 0.1733 - val_loss: 1.8041 - val_categorical_accuracy: 0.1556\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7927 - categorical_accuracy: 0.1733 - val_loss: 1.8047 - val_categorical_accuracy: 0.1556\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7925 - categorical_accuracy: 0.1689 - val_loss: 1.8028 - val_categorical_accuracy: 0.1556\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7921 - categorical_accuracy: 0.1778 - val_loss: 1.8026 - val_categorical_accuracy: 0.1556\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7922 - categorical_accuracy: 0.1778 - val_loss: 1.8036 - val_categorical_accuracy: 0.1556\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.7923 - categorical_accuracy: 0.1778 - val_loss: 1.8043 - val_categorical_accuracy: 0.1556\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7920 - categorical_accuracy: 0.1778 - val_loss: 1.8020 - val_categorical_accuracy: 0.1556\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.7919 - categorical_accuracy: 0.1778 - val_loss: 1.7992 - val_categorical_accuracy: 0.1556\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7923 - categorical_accuracy: 0.1778 - val_loss: 1.7987 - val_categorical_accuracy: 0.1556\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7917 - categorical_accuracy: 0.1778 - val_loss: 1.7995 - val_categorical_accuracy: 0.1556\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.8004 - val_categorical_accuracy: 0.1556\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7917 - categorical_accuracy: 0.1778 - val_loss: 1.7994 - val_categorical_accuracy: 0.1556\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7919 - categorical_accuracy: 0.1778 - val_loss: 1.7994 - val_categorical_accuracy: 0.1556\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7918 - categorical_accuracy: 0.1778 - val_loss: 1.8001 - val_categorical_accuracy: 0.1556\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.7989 - val_categorical_accuracy: 0.1556\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7969 - val_categorical_accuracy: 0.1556\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.7947 - val_categorical_accuracy: 0.1556\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.7951 - val_categorical_accuracy: 0.1556\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.7957 - val_categorical_accuracy: 0.1556\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.7954 - val_categorical_accuracy: 0.1556\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.7965 - val_categorical_accuracy: 0.1556\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.7922 - categorical_accuracy: 0.1733 - val_loss: 1.7984 - val_categorical_accuracy: 0.1333\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7919 - categorical_accuracy: 0.1689 - val_loss: 1.8001 - val_categorical_accuracy: 0.1333\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7920 - categorical_accuracy: 0.1289 - val_loss: 1.8012 - val_categorical_accuracy: 0.1556\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.8015 - val_categorical_accuracy: 0.1556\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7998 - val_categorical_accuracy: 0.1556\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.7917 - categorical_accuracy: 0.1778 - val_loss: 1.7996 - val_categorical_accuracy: 0.1556\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7909 - categorical_accuracy: 0.1778 - val_loss: 1.8006 - val_categorical_accuracy: 0.1556\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7911 - categorical_accuracy: 0.1778 - val_loss: 1.8020 - val_categorical_accuracy: 0.1556\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7911 - categorical_accuracy: 0.1778 - val_loss: 1.8027 - val_categorical_accuracy: 0.1556\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.8007 - val_categorical_accuracy: 0.1556\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7917 - categorical_accuracy: 0.1778 - val_loss: 1.7981 - val_categorical_accuracy: 0.1556\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.7973 - val_categorical_accuracy: 0.1556\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.7954 - val_categorical_accuracy: 0.1556\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7921 - categorical_accuracy: 0.1778 - val_loss: 1.7935 - val_categorical_accuracy: 0.1556\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.7921 - categorical_accuracy: 0.1778 - val_loss: 1.7941 - val_categorical_accuracy: 0.1556\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7947 - val_categorical_accuracy: 0.1556\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7939 - val_categorical_accuracy: 0.1556\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7923 - categorical_accuracy: 0.1422 - val_loss: 1.7923 - val_categorical_accuracy: 0.1556\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 1.7921 - categorical_accuracy: 0.1778 - val_loss: 1.7926 - val_categorical_accuracy: 0.1556\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7921 - categorical_accuracy: 0.1778 - val_loss: 1.7943 - val_categorical_accuracy: 0.1556\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7952 - val_categorical_accuracy: 0.1556\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7942 - val_categorical_accuracy: 0.1556\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7918 - categorical_accuracy: 0.1778 - val_loss: 1.7926 - val_categorical_accuracy: 0.1556\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.7925 - val_categorical_accuracy: 0.1556\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.7918 - categorical_accuracy: 0.1778 - val_loss: 1.7938 - val_categorical_accuracy: 0.1556\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7912 - categorical_accuracy: 0.1778 - val_loss: 1.7948 - val_categorical_accuracy: 0.1556\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7910 - categorical_accuracy: 0.1733 - val_loss: 1.7945 - val_categorical_accuracy: 0.1556\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7917 - categorical_accuracy: 0.1733 - val_loss: 1.7955 - val_categorical_accuracy: 0.1556\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7908 - categorical_accuracy: 0.2044 - val_loss: 1.7968 - val_categorical_accuracy: 0.1556\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7909 - categorical_accuracy: 0.1778 - val_loss: 1.7979 - val_categorical_accuracy: 0.1556\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.7909 - categorical_accuracy: 0.1778 - val_loss: 1.7969 - val_categorical_accuracy: 0.1556\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7912 - categorical_accuracy: 0.1778 - val_loss: 1.7979 - val_categorical_accuracy: 0.1556\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7910 - categorical_accuracy: 0.1644 - val_loss: 1.7993 - val_categorical_accuracy: 0.1333\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.7915 - categorical_accuracy: 0.1689 - val_loss: 1.8007 - val_categorical_accuracy: 0.1556\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.7914 - categorical_accuracy: 0.1778 - val_loss: 1.8016 - val_categorical_accuracy: 0.1556\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7911 - categorical_accuracy: 0.1778 - val_loss: 1.8026 - val_categorical_accuracy: 0.1556\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7912 - categorical_accuracy: 0.1778 - val_loss: 1.8039 - val_categorical_accuracy: 0.1556\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 1.7915 - categorical_accuracy: 0.1778 - val_loss: 1.8049 - val_categorical_accuracy: 0.1556\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.7920 - categorical_accuracy: 0.1778 - val_loss: 1.8064 - val_categorical_accuracy: 0.1556\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7931 - categorical_accuracy: 0.1778 - val_loss: 1.8069 - val_categorical_accuracy: 0.1556\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7926 - categorical_accuracy: 0.1778 - val_loss: 1.8053 - val_categorical_accuracy: 0.1556\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7925 - categorical_accuracy: 0.1778 - val_loss: 1.8032 - val_categorical_accuracy: 0.1556\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 1.7927 - categorical_accuracy: 0.1778 - val_loss: 1.8035 - val_categorical_accuracy: 0.1556\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.7924 - categorical_accuracy: 0.1778 - val_loss: 1.8041 - val_categorical_accuracy: 0.1556\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.7924 - categorical_accuracy: 0.1778 - val_loss: 1.8050 - val_categorical_accuracy: 0.1556\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.7918 - categorical_accuracy: 0.1778 - val_loss: 1.8038 - val_categorical_accuracy: 0.1556\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.7916 - categorical_accuracy: 0.1778 - val_loss: 1.8024 - val_categorical_accuracy: 0.1556\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.7923 - categorical_accuracy: 0.1778 - val_loss: 1.8023 - val_categorical_accuracy: 0.1556\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.7920 - categorical_accuracy: 0.1778 - val_loss: 1.8026 - val_categorical_accuracy: 0.1556\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.7920 - categorical_accuracy: 0.1778 - val_loss: 1.8036 - val_categorical_accuracy: 0.1556\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.7922 - categorical_accuracy: 0.1778 - val_loss: 1.8049 - val_categorical_accuracy: 0.1556\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7929 - categorical_accuracy: 0.1778 - val_loss: 1.8066 - val_categorical_accuracy: 0.1556\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.7933 - categorical_accuracy: 0.1778 - val_loss: 1.8081 - val_categorical_accuracy: 0.1556\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 1.7939 - categorical_accuracy: 0.1778 - val_loss: 1.8092 - val_categorical_accuracy: 0.1556\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.7936 - categorical_accuracy: 0.1778 - val_loss: 1.8105 - val_categorical_accuracy: 0.1556\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7935 - categorical_accuracy: 0.1778 - val_loss: 1.8105 - val_categorical_accuracy: 0.1556\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.7934 - categorical_accuracy: 0.1778 - val_loss: 1.8118 - val_categorical_accuracy: 0.1556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21c492a1550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "lstm.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f7ef533-9f4d-4e8d-a773-fe93f2f631fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard logging and callbacks\n",
    "NAME = f\"ExerciseRecognition-AttnLSTM-{int(time.time())}\"\n",
    "log_dir = os.path.join(os.getcwd(), 'logs', NAME,'')\n",
    "#tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#callbacks = [tb_callback, es_callback, lr_callback, chkpt_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8a9d650-28a2-4605-906a-7ad92c708b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention_block(inputs, time_steps):\n",
    "    \"\"\"\n",
    "    Attention layer for deep neural network\n",
    "    \n",
    "    \"\"\"\n",
    "    # Attention weights\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(time_steps, activation='softmax')(a)\n",
    "    \n",
    "    # Attention vector\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    \n",
    "    # Luong's multiplicative score\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul') \n",
    "    \n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89973d6a-bc65-4d69-a8cf-f981bd67d989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 132)]            0         []                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 30, 512)              796672    ['input_1[0][0]']             \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 512, 30)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512, 30)              930       ['permute[0][0]']             \n",
      "                                                                                                  \n",
      " attention_vec (Permute)     (None, 30, 512)              0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " attention_mul (Multiply)    (None, 30, 512)              0         ['bidirectional[0][0]',       \n",
      "                                                                     'attention_vec[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 15360)                0         ['attention_mul[0][0]']       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  7864832   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    3078      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8665512 (33.06 MB)\n",
      "Trainable params: 8665512 (33.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = 256\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=(sequence_length, num_input_values))\n",
    "\n",
    "# Bi-LSTM\n",
    "lstm_out = Bidirectional(LSTM(HIDDEN_UNITS, return_sequences=True))(inputs)\n",
    "\n",
    "# Attention\n",
    "attention_mul = attention_block(lstm_out, sequence_length)\n",
    "attention_mul = Flatten()(attention_mul)\n",
    "\n",
    "# Fully Connected Layer\n",
    "x = Dense(2*HIDDEN_UNITS, activation='relu')(attention_mul)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output\n",
    "x = Dense(actions.shape[0], activation='softmax')(x)\n",
    "\n",
    "# Bring it all together\n",
    "AttnLSTM = Model(inputs=[inputs], outputs=x)\n",
    "print(AttnLSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45e5a32-5f14-48c5-84ed-067fdc4bbf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 10s 304ms/step - loss: 1.6101 - categorical_accuracy: 0.3378 - val_loss: 1.1719 - val_categorical_accuracy: 0.3111\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.9969 - categorical_accuracy: 0.5600 - val_loss: 0.7002 - val_categorical_accuracy: 0.7333\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.7721 - categorical_accuracy: 0.6756 - val_loss: 0.3391 - val_categorical_accuracy: 0.8222\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.5853 - categorical_accuracy: 0.7867 - val_loss: 0.6448 - val_categorical_accuracy: 0.7111\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.6038 - categorical_accuracy: 0.7467 - val_loss: 0.4277 - val_categorical_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.5378 - categorical_accuracy: 0.7867 - val_loss: 0.5673 - val_categorical_accuracy: 0.7778\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.6457 - categorical_accuracy: 0.7244 - val_loss: 0.3946 - val_categorical_accuracy: 0.8222\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.4360 - categorical_accuracy: 0.8000 - val_loss: 0.4871 - val_categorical_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 1.1240 - categorical_accuracy: 0.6400 - val_loss: 0.6316 - val_categorical_accuracy: 0.7333\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.7797 - categorical_accuracy: 0.6444 - val_loss: 0.3902 - val_categorical_accuracy: 0.8222\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.5067 - categorical_accuracy: 0.7689 - val_loss: 0.3621 - val_categorical_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.5065 - categorical_accuracy: 0.7689 - val_loss: 0.4258 - val_categorical_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.5285 - categorical_accuracy: 0.7689 - val_loss: 0.2926 - val_categorical_accuracy: 0.8222\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4482 - categorical_accuracy: 0.8178 - val_loss: 0.2453 - val_categorical_accuracy: 0.8222\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.4032 - categorical_accuracy: 0.8044 - val_loss: 0.3204 - val_categorical_accuracy: 0.8444\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.3702 - categorical_accuracy: 0.8489 - val_loss: 0.1971 - val_categorical_accuracy: 0.9333\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.2892 - categorical_accuracy: 0.8889 - val_loss: 0.2519 - val_categorical_accuracy: 0.8444\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.3145 - categorical_accuracy: 0.8667 - val_loss: 0.1670 - val_categorical_accuracy: 0.9556\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.2878 - categorical_accuracy: 0.8933 - val_loss: 0.1973 - val_categorical_accuracy: 0.9556\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.3810 - categorical_accuracy: 0.8489 - val_loss: 0.1792 - val_categorical_accuracy: 0.9111\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.2252 - categorical_accuracy: 0.9200 - val_loss: 0.1838 - val_categorical_accuracy: 0.9333\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.2418 - categorical_accuracy: 0.9156 - val_loss: 0.1884 - val_categorical_accuracy: 0.8889\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.2948 - categorical_accuracy: 0.8800 - val_loss: 0.1821 - val_categorical_accuracy: 0.8889\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.2265 - categorical_accuracy: 0.9111 - val_loss: 0.4118 - val_categorical_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.6690 - categorical_accuracy: 0.7867 - val_loss: 0.3177 - val_categorical_accuracy: 0.8667\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.2924 - categorical_accuracy: 0.8889 - val_loss: 0.4363 - val_categorical_accuracy: 0.8444\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.3307 - categorical_accuracy: 0.8622 - val_loss: 0.3253 - val_categorical_accuracy: 0.8222\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.2812 - categorical_accuracy: 0.9022 - val_loss: 0.0989 - val_categorical_accuracy: 0.9778\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1687 - categorical_accuracy: 0.9378 - val_loss: 0.1674 - val_categorical_accuracy: 0.9111\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.2231 - categorical_accuracy: 0.9022 - val_loss: 0.1358 - val_categorical_accuracy: 0.9778\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.2036 - categorical_accuracy: 0.9244 - val_loss: 0.3306 - val_categorical_accuracy: 0.8444\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.3351 - categorical_accuracy: 0.8533 - val_loss: 1.0072 - val_categorical_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 1.0973 - categorical_accuracy: 0.6844 - val_loss: 0.2222 - val_categorical_accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.6446 - categorical_accuracy: 0.7689 - val_loss: 0.3774 - val_categorical_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.4086 - categorical_accuracy: 0.8578 - val_loss: 0.2210 - val_categorical_accuracy: 0.9556\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3340 - categorical_accuracy: 0.8889 - val_loss: 0.1637 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1961 - categorical_accuracy: 0.9333 - val_loss: 0.1063 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.1610 - categorical_accuracy: 0.9422 - val_loss: 0.1115 - val_categorical_accuracy: 0.9778\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1512 - categorical_accuracy: 0.9378 - val_loss: 0.1038 - val_categorical_accuracy: 0.9778\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.1159 - categorical_accuracy: 0.9556 - val_loss: 0.0625 - val_categorical_accuracy: 0.9778\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1066 - categorical_accuracy: 0.9644 - val_loss: 0.0438 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1166 - categorical_accuracy: 0.9556 - val_loss: 0.1621 - val_categorical_accuracy: 0.9556\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1802 - categorical_accuracy: 0.9067 - val_loss: 0.2482 - val_categorical_accuracy: 0.8889\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2159 - categorical_accuracy: 0.9200 - val_loss: 0.0965 - val_categorical_accuracy: 0.9556\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.1683 - categorical_accuracy: 0.9467 - val_loss: 0.1013 - val_categorical_accuracy: 0.9556\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.1278 - categorical_accuracy: 0.9467 - val_loss: 0.2473 - val_categorical_accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.3042 - categorical_accuracy: 0.8844 - val_loss: 0.1970 - val_categorical_accuracy: 0.8889\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.2170 - categorical_accuracy: 0.9244 - val_loss: 0.2744 - val_categorical_accuracy: 0.9111\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.1354 - categorical_accuracy: 0.9511 - val_loss: 0.1309 - val_categorical_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.2163 - categorical_accuracy: 0.9422 - val_loss: 0.1015 - val_categorical_accuracy: 0.9778\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.1234 - categorical_accuracy: 0.9600 - val_loss: 0.1358 - val_categorical_accuracy: 0.9556\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.1123 - categorical_accuracy: 0.9600 - val_loss: 0.1399 - val_categorical_accuracy: 0.9778\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0665 - categorical_accuracy: 0.9867 - val_loss: 0.0401 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0735 - categorical_accuracy: 0.9689 - val_loss: 0.1485 - val_categorical_accuracy: 0.9556\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.0972 - categorical_accuracy: 0.9644 - val_loss: 0.1526 - val_categorical_accuracy: 0.9778\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1655 - categorical_accuracy: 0.9289 - val_loss: 0.0989 - val_categorical_accuracy: 0.9778\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.1758 - categorical_accuracy: 0.9200 - val_loss: 0.0951 - val_categorical_accuracy: 0.9778\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.1027 - categorical_accuracy: 0.9556 - val_loss: 0.0532 - val_categorical_accuracy: 0.9778\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0630 - categorical_accuracy: 0.9733 - val_loss: 0.0196 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0629 - categorical_accuracy: 0.9733 - val_loss: 0.0475 - val_categorical_accuracy: 0.9778\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0480 - categorical_accuracy: 0.9867 - val_loss: 0.1796 - val_categorical_accuracy: 0.9778\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0533 - categorical_accuracy: 0.9822 - val_loss: 0.0383 - val_categorical_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0425 - categorical_accuracy: 0.9822 - val_loss: 0.0102 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.1106 - categorical_accuracy: 0.9556 - val_loss: 0.0207 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.0706 - categorical_accuracy: 0.9733 - val_loss: 0.0421 - val_categorical_accuracy: 0.9778\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0926 - categorical_accuracy: 0.9600 - val_loss: 0.0810 - val_categorical_accuracy: 0.9778\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0950 - categorical_accuracy: 0.9733 - val_loss: 0.0786 - val_categorical_accuracy: 0.9778\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0553 - categorical_accuracy: 0.9778 - val_loss: 0.0450 - val_categorical_accuracy: 0.9778\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0530 - categorical_accuracy: 0.9822 - val_loss: 0.0452 - val_categorical_accuracy: 0.9778\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0315 - categorical_accuracy: 0.9867 - val_loss: 0.0523 - val_categorical_accuracy: 0.9778\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1944 - categorical_accuracy: 0.9244 - val_loss: 0.1138 - val_categorical_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.1318 - categorical_accuracy: 0.9556 - val_loss: 0.0583 - val_categorical_accuracy: 0.9778\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0452 - categorical_accuracy: 0.9867 - val_loss: 0.0265 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0664 - categorical_accuracy: 0.9778 - val_loss: 0.0424 - val_categorical_accuracy: 0.9778\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.7035 - categorical_accuracy: 0.8578 - val_loss: 0.3685 - val_categorical_accuracy: 0.8444\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.4431 - categorical_accuracy: 0.8089 - val_loss: 0.2609 - val_categorical_accuracy: 0.8667\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.3331 - categorical_accuracy: 0.8667 - val_loss: 0.1491 - val_categorical_accuracy: 0.9556\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.2354 - categorical_accuracy: 0.9067 - val_loss: 0.1411 - val_categorical_accuracy: 0.9778\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.2189 - categorical_accuracy: 0.9067 - val_loss: 0.0731 - val_categorical_accuracy: 0.9778\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.1696 - categorical_accuracy: 0.9378 - val_loss: 0.1567 - val_categorical_accuracy: 0.9556\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.1266 - categorical_accuracy: 0.9733 - val_loss: 0.1114 - val_categorical_accuracy: 0.9556\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.1088 - categorical_accuracy: 0.9600 - val_loss: 0.0933 - val_categorical_accuracy: 0.9556\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1022 - categorical_accuracy: 0.9733 - val_loss: 0.0443 - val_categorical_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0893 - categorical_accuracy: 0.9733 - val_loss: 0.0835 - val_categorical_accuracy: 0.9778\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0867 - categorical_accuracy: 0.9644 - val_loss: 0.0678 - val_categorical_accuracy: 0.9778\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0541 - categorical_accuracy: 0.9778 - val_loss: 0.0590 - val_categorical_accuracy: 0.9778\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0646 - categorical_accuracy: 0.9733 - val_loss: 0.0165 - val_categorical_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0533 - categorical_accuracy: 0.9778 - val_loss: 0.0512 - val_categorical_accuracy: 0.9778\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0471 - categorical_accuracy: 0.9822 - val_loss: 0.0147 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0711 - categorical_accuracy: 0.9644 - val_loss: 0.0674 - val_categorical_accuracy: 0.9778\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0588 - categorical_accuracy: 0.9822 - val_loss: 0.0198 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0646 - categorical_accuracy: 0.9733 - val_loss: 0.0151 - val_categorical_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0697 - categorical_accuracy: 0.9689 - val_loss: 0.0135 - val_categorical_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0761 - categorical_accuracy: 0.9733 - val_loss: 0.0695 - val_categorical_accuracy: 0.9778\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0654 - categorical_accuracy: 0.9689 - val_loss: 0.0265 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0835 - categorical_accuracy: 0.9556 - val_loss: 0.1325 - val_categorical_accuracy: 0.9556\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0571 - categorical_accuracy: 0.9778 - val_loss: 0.0279 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0744 - categorical_accuracy: 0.9689 - val_loss: 0.0150 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0416 - categorical_accuracy: 0.9911 - val_loss: 0.0403 - val_categorical_accuracy: 0.9778\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0408 - categorical_accuracy: 0.9822 - val_loss: 0.0402 - val_categorical_accuracy: 0.9778\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0218 - categorical_accuracy: 0.9956 - val_loss: 0.0217 - val_categorical_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0242 - categorical_accuracy: 0.9911 - val_loss: 0.0225 - val_categorical_accuracy: 0.9778\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0559 - categorical_accuracy: 0.9822 - val_loss: 0.2257 - val_categorical_accuracy: 0.9556\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.1549 - categorical_accuracy: 0.9378 - val_loss: 0.1935 - val_categorical_accuracy: 0.9778\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.1878 - categorical_accuracy: 0.9422 - val_loss: 0.0780 - val_categorical_accuracy: 0.9778\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.6497 - categorical_accuracy: 0.8578 - val_loss: 0.9530 - val_categorical_accuracy: 0.7556\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.8642 - categorical_accuracy: 0.7156 - val_loss: 0.1463 - val_categorical_accuracy: 0.9556\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3593 - categorical_accuracy: 0.9022 - val_loss: 0.2389 - val_categorical_accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2634 - categorical_accuracy: 0.9111 - val_loss: 0.0705 - val_categorical_accuracy: 0.9778\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.1694 - categorical_accuracy: 0.9511 - val_loss: 0.1858 - val_categorical_accuracy: 0.8889\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.2935 - categorical_accuracy: 0.8933 - val_loss: 0.4238 - val_categorical_accuracy: 0.8444\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.3070 - categorical_accuracy: 0.8667 - val_loss: 0.1529 - val_categorical_accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.1265 - categorical_accuracy: 0.9689 - val_loss: 0.1670 - val_categorical_accuracy: 0.9778\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.1537 - categorical_accuracy: 0.9644 - val_loss: 0.0727 - val_categorical_accuracy: 0.9778\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1107 - categorical_accuracy: 0.9689 - val_loss: 0.0880 - val_categorical_accuracy: 0.9778\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.1574 - categorical_accuracy: 0.9511 - val_loss: 0.1673 - val_categorical_accuracy: 0.9778\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.0989 - categorical_accuracy: 0.9422 - val_loss: 0.0806 - val_categorical_accuracy: 0.9778\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0766 - categorical_accuracy: 0.9822 - val_loss: 0.0950 - val_categorical_accuracy: 0.9778\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0790 - categorical_accuracy: 0.9778 - val_loss: 0.1224 - val_categorical_accuracy: 0.9778\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0766 - categorical_accuracy: 0.9733 - val_loss: 0.0829 - val_categorical_accuracy: 0.9778\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0660 - categorical_accuracy: 0.9778 - val_loss: 0.0647 - val_categorical_accuracy: 0.9778\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0730 - categorical_accuracy: 0.9733 - val_loss: 0.0464 - val_categorical_accuracy: 0.9778\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0516 - categorical_accuracy: 0.9822 - val_loss: 0.0366 - val_categorical_accuracy: 0.9778\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0363 - categorical_accuracy: 0.9911 - val_loss: 0.0445 - val_categorical_accuracy: 0.9778\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0495 - categorical_accuracy: 0.9867 - val_loss: 0.0496 - val_categorical_accuracy: 0.9778\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0616 - categorical_accuracy: 0.9644 - val_loss: 0.0435 - val_categorical_accuracy: 0.9778\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0417 - categorical_accuracy: 0.9867 - val_loss: 0.0379 - val_categorical_accuracy: 0.9778\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0348 - categorical_accuracy: 0.9911 - val_loss: 0.0557 - val_categorical_accuracy: 0.9778\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0368 - categorical_accuracy: 0.9867 - val_loss: 0.0583 - val_categorical_accuracy: 0.9778\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0391 - categorical_accuracy: 0.9822 - val_loss: 0.0471 - val_categorical_accuracy: 0.9778\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.0359 - categorical_accuracy: 0.9867 - val_loss: 0.0444 - val_categorical_accuracy: 0.9778\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0185 - categorical_accuracy: 0.9911 - val_loss: 0.0432 - val_categorical_accuracy: 0.9778\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.0343 - categorical_accuracy: 0.9822 - val_loss: 0.0949 - val_categorical_accuracy: 0.9778\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0984 - categorical_accuracy: 0.9778 - val_loss: 0.0465 - val_categorical_accuracy: 0.9778\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0502 - categorical_accuracy: 0.9867 - val_loss: 0.0155 - val_categorical_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0418 - categorical_accuracy: 0.9867 - val_loss: 0.0885 - val_categorical_accuracy: 0.9778\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0265 - categorical_accuracy: 0.9867 - val_loss: 0.1317 - val_categorical_accuracy: 0.9778\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0336 - categorical_accuracy: 0.9867 - val_loss: 0.0907 - val_categorical_accuracy: 0.9778\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0211 - categorical_accuracy: 0.9956 - val_loss: 0.0527 - val_categorical_accuracy: 0.9778\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0209 - categorical_accuracy: 0.9867 - val_loss: 0.0573 - val_categorical_accuracy: 0.9778\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0187 - categorical_accuracy: 0.9956 - val_loss: 0.0738 - val_categorical_accuracy: 0.9778\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0263 - categorical_accuracy: 0.9911 - val_loss: 0.0730 - val_categorical_accuracy: 0.9778\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.0126 - categorical_accuracy: 1.0000 - val_loss: 0.0812 - val_categorical_accuracy: 0.9778\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0185 - categorical_accuracy: 0.9956 - val_loss: 0.0642 - val_categorical_accuracy: 0.9778\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0118 - categorical_accuracy: 1.0000 - val_loss: 0.0601 - val_categorical_accuracy: 0.9778\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0159 - categorical_accuracy: 1.0000 - val_loss: 0.0658 - val_categorical_accuracy: 0.9778\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0115 - categorical_accuracy: 0.9956 - val_loss: 0.0699 - val_categorical_accuracy: 0.9778\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0079 - categorical_accuracy: 0.9956 - val_loss: 0.0451 - val_categorical_accuracy: 0.9778\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0064 - categorical_accuracy: 1.0000 - val_loss: 0.0510 - val_categorical_accuracy: 0.9778\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.0069 - categorical_accuracy: 1.0000 - val_loss: 0.0623 - val_categorical_accuracy: 0.9778\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0065 - categorical_accuracy: 0.9956 - val_loss: 0.0642 - val_categorical_accuracy: 0.9778\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 0.0440 - val_categorical_accuracy: 0.9778\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.0054 - categorical_accuracy: 1.0000 - val_loss: 0.0460 - val_categorical_accuracy: 0.9778\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.0070 - categorical_accuracy: 0.9956 - val_loss: 0.0434 - val_categorical_accuracy: 0.9778\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 0.0135 - categorical_accuracy: 0.9956 - val_loss: 0.0296 - val_categorical_accuracy: 0.9778\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0256 - categorical_accuracy: 0.9956 - val_loss: 0.0172 - val_categorical_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0058 - categorical_accuracy: 1.0000 - val_loss: 0.0162 - val_categorical_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0114 - categorical_accuracy: 1.0000 - val_loss: 0.0330 - val_categorical_accuracy: 0.9778\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0153 - categorical_accuracy: 0.9956 - val_loss: 0.0508 - val_categorical_accuracy: 0.9778\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0106 - categorical_accuracy: 1.0000 - val_loss: 0.0578 - val_categorical_accuracy: 0.9778\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0091 - categorical_accuracy: 0.9956 - val_loss: 0.0598 - val_categorical_accuracy: 0.9778\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.0612 - val_categorical_accuracy: 0.9778\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 0.0102 - categorical_accuracy: 0.9956 - val_loss: 0.0610 - val_categorical_accuracy: 0.9778\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0060 - categorical_accuracy: 0.9956 - val_loss: 0.0578 - val_categorical_accuracy: 0.9778\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.0598 - val_categorical_accuracy: 0.9778\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.0558 - val_categorical_accuracy: 0.9778\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.0675 - val_categorical_accuracy: 0.9778\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.0709 - val_categorical_accuracy: 0.9778\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0044 - categorical_accuracy: 1.0000 - val_loss: 0.0670 - val_categorical_accuracy: 0.9778\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.0431 - val_categorical_accuracy: 0.9778\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.0500 - val_categorical_accuracy: 0.9778\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.0547 - val_categorical_accuracy: 0.9778\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0054 - categorical_accuracy: 1.0000 - val_loss: 0.0222 - val_categorical_accuracy: 0.9778\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0055 - categorical_accuracy: 1.0000 - val_loss: 0.0293 - val_categorical_accuracy: 0.9778\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.0576 - val_categorical_accuracy: 0.9778\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 0.0585 - val_categorical_accuracy: 0.9778\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.0055 - categorical_accuracy: 1.0000 - val_loss: 0.0110 - val_categorical_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.0101 - val_categorical_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 0.0200 - val_categorical_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.2011 - categorical_accuracy: 0.9600 - val_loss: 0.2716 - val_categorical_accuracy: 0.9556\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.7558 - categorical_accuracy: 0.8267 - val_loss: 0.9933 - val_categorical_accuracy: 0.6444\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.3945 - categorical_accuracy: 0.8800 - val_loss: 0.0588 - val_categorical_accuracy: 0.9778\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.1740 - categorical_accuracy: 0.8978 - val_loss: 0.0849 - val_categorical_accuracy: 0.9778\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.1066 - categorical_accuracy: 0.9600 - val_loss: 0.0708 - val_categorical_accuracy: 0.9778\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0535 - categorical_accuracy: 0.9867 - val_loss: 0.0548 - val_categorical_accuracy: 0.9778\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0418 - categorical_accuracy: 0.9867 - val_loss: 0.0600 - val_categorical_accuracy: 0.9778\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.0237 - categorical_accuracy: 0.9956 - val_loss: 0.0554 - val_categorical_accuracy: 0.9778\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0266 - categorical_accuracy: 0.9911 - val_loss: 0.0582 - val_categorical_accuracy: 0.9778\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.0492 - categorical_accuracy: 0.9778 - val_loss: 0.1610 - val_categorical_accuracy: 0.9778\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0607 - categorical_accuracy: 0.9822 - val_loss: 0.0691 - val_categorical_accuracy: 0.9778\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0395 - categorical_accuracy: 0.9822 - val_loss: 0.0374 - val_categorical_accuracy: 0.9778\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0329 - categorical_accuracy: 0.9911 - val_loss: 0.3197 - val_categorical_accuracy: 0.8889\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.9461 - categorical_accuracy: 0.8178 - val_loss: 0.5090 - val_categorical_accuracy: 0.7556\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.4421 - categorical_accuracy: 0.8133 - val_loss: 0.2344 - val_categorical_accuracy: 0.8889\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.3609 - categorical_accuracy: 0.8800 - val_loss: 0.1022 - val_categorical_accuracy: 0.9556\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.1806 - categorical_accuracy: 0.9156 - val_loss: 0.1914 - val_categorical_accuracy: 0.9556\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.1721 - categorical_accuracy: 0.9333 - val_loss: 0.0796 - val_categorical_accuracy: 0.9778\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1314 - categorical_accuracy: 0.9600 - val_loss: 0.1352 - val_categorical_accuracy: 0.9556\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.2182 - categorical_accuracy: 0.9244 - val_loss: 0.0473 - val_categorical_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1405 - categorical_accuracy: 0.9378 - val_loss: 0.1893 - val_categorical_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "AttnLSTM.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "history=AttnLSTM.fit(X_train, y_train, batch_size=batch_size, epochs=max_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a025a2c2-36f5-4d07-bde9-be375b10e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train loss','validation loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04a9473d-b07c-44e2-b81f-7f22ef6afc54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Model map\u001b[39;00m\n\u001b[0;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m: lstm, \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM_Attention_128HUs\u001b[39m\u001b[38;5;124m'\u001b[39m: AttnLSTM, \n\u001b[0;32m      5\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm' is not defined"
     ]
    }
   ],
   "source": [
    "# Model map\n",
    "models = {\n",
    "    'LSTM': lstm, \n",
    "    'LSTM_Attention_128HUs': AttnLSTM, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5067e22d-9a1e-43b4-8450-53b08571a1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    save_dir = os.path.join(os.getcwd(), f\"{model_name}.h5\")\n",
    "    model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aab8f61-1328-41b4-bcba-134c084cf1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run model rebuild before doing this\n",
    "for model_name, model in models.items():\n",
    "    load_dir = os.path.join(os.getcwd(), f\"{model_name}.h5\")\n",
    "    model.load_weights(load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f338317-47f2-49d5-a29b-733e4b2d6c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]\n",
      " [0.13977863 0.17301555 0.1556387  0.15647677 0.20298097 0.17210941]]\n",
      "[[9.47434839e-11 6.33849695e-10 8.26471578e-03 9.90634501e-01\n",
      "  1.10076729e-03 1.04261684e-08]\n",
      " [4.28380690e-06 7.00294413e-06 9.99790013e-01 4.62924872e-05\n",
      "  1.49512372e-04 2.90165326e-06]\n",
      " [1.85492125e-11 1.30730551e-10 1.25817780e-03 9.98153746e-01\n",
      "  5.88042196e-04 2.14928297e-09]\n",
      " [4.90419608e-13 2.71273091e-11 1.65189272e-06 1.12175430e-05\n",
      "  9.99987006e-01 1.22174455e-07]\n",
      " [4.39277646e-04 7.21618650e-04 9.98107076e-01 2.29381098e-04\n",
      "  4.08974680e-04 9.37174336e-05]\n",
      " [7.70484039e-05 8.05984819e-05 9.99737084e-01 1.44989353e-05\n",
      "  8.35733081e-05 7.21555625e-06]\n",
      " [6.04363504e-10 5.92728533e-09 6.28111064e-02 9.33397114e-01\n",
      "  3.79160629e-03 7.67340893e-08]\n",
      " [1.11482968e-03 9.81533229e-01 6.18443650e-04 2.05333617e-05\n",
      "  4.24138761e-07 1.67126432e-02]\n",
      " [1.19879289e-04 2.10124567e-01 5.22323244e-04 1.91086321e-04\n",
      "  1.51935737e-05 7.89026916e-01]\n",
      " [2.88875233e-13 1.77128815e-11 1.04068465e-06 8.24068957e-06\n",
      "  9.99990582e-01 1.04982597e-07]\n",
      " [1.06521302e-05 3.03766318e-03 1.56377035e-03 1.28569693e-04\n",
      "  5.51392382e-04 9.94708061e-01]\n",
      " [1.71828258e-08 4.61059017e-07 9.99981880e-01 7.68606878e-06\n",
      "  8.18215995e-06 1.77544439e-06]\n",
      " [3.38974351e-05 1.16293104e-02 1.33704289e-03 3.03187320e-04\n",
      "  3.20309395e-04 9.86376345e-01]\n",
      " [6.02490976e-02 8.82025003e-01 5.68239130e-02 3.32757663e-05\n",
      "  2.36508072e-06 8.66386690e-04]\n",
      " [6.28519729e-06 2.45944047e-05 9.99494433e-01 1.29431661e-04\n",
      "  3.31998890e-04 1.32669893e-05]\n",
      " [3.27594802e-02 9.20840383e-01 4.52745333e-02 3.13232595e-05\n",
      "  2.02503225e-06 1.09233300e-03]\n",
      " [9.99987006e-01 7.67887650e-06 5.38551058e-06 8.06247180e-10\n",
      "  1.55609744e-11 2.46900211e-09]\n",
      " [3.67163439e-10 1.82775706e-09 6.67099934e-03 9.92253840e-01\n",
      "  1.07521797e-03 6.18415319e-09]\n",
      " [4.57985321e-13 2.47198668e-11 1.30176215e-06 1.15284156e-05\n",
      "  9.99987006e-01 1.07680684e-07]\n",
      " [9.99983549e-01 1.05249837e-05 5.97763210e-06 3.15445781e-10\n",
      "  6.87924674e-12 2.84274804e-09]\n",
      " [9.99987364e-01 4.83355461e-06 7.77363493e-06 7.40276035e-11\n",
      "  5.63427733e-12 1.23561039e-09]\n",
      " [1.25821726e-08 1.62371180e-07 9.99963641e-01 1.13911237e-05\n",
      "  2.43059039e-05 4.36736286e-07]\n",
      " [2.80524296e-06 2.78489524e-03 1.78883362e-04 2.63787242e-05\n",
      "  4.18713862e-05 9.96965110e-01]\n",
      " [9.99993563e-01 5.65490382e-06 8.43275473e-07 1.94908534e-10\n",
      "  2.24178575e-12 1.50293178e-09]\n",
      " [2.45222436e-05 1.03497427e-04 9.99706924e-01 9.11903917e-05\n",
      "  6.56717530e-05 8.10087295e-06]\n",
      " [9.99989390e-01 1.04820519e-05 1.04049526e-07 1.43216489e-11\n",
      "  5.68581030e-14 6.20859752e-10]\n",
      " [2.73929145e-05 4.07659402e-03 5.62221650e-03 4.13122936e-04\n",
      "  2.33362964e-03 9.87527072e-01]\n",
      " [3.37431133e-02 7.14179933e-01 2.50457227e-01 7.03619953e-05\n",
      "  1.20672994e-05 1.53744244e-03]\n",
      " [1.47302335e-05 2.38513779e-02 1.57451752e-04 8.52351004e-05\n",
      "  1.52683515e-05 9.75875914e-01]\n",
      " [5.91134919e-11 6.53161081e-10 4.82210424e-03 9.94468093e-01\n",
      "  7.09833344e-04 6.35879349e-09]]\n"
     ]
    }
   ],
   "source": [
    "for model in models.values():\n",
    "    res = model.predict(X_test, verbose=0)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "335c7db9-b504-4e53-9a2e-2007c286d8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_results = {}\n",
    "eval_results['confusion matrix'] = None\n",
    "eval_results['accuracy'] = None\n",
    "eval_results['precision'] = None\n",
    "eval_results['recall'] = None\n",
    "eval_results['f1 score'] = None\n",
    "\n",
    "confusion_matrices = {}\n",
    "classification_accuracies = {}   \n",
    "precisions = {}\n",
    "recalls = {}\n",
    "f1_scores = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad7be8e8-c74d-4f3d-826e-b4d730b72987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM confusion matrix: \n",
      "[[[25  0]\n",
      "  [ 5  0]]\n",
      "\n",
      " [[26  0]\n",
      "  [ 4  0]]\n",
      "\n",
      " [[23  0]\n",
      "  [ 7  0]]\n",
      "\n",
      " [[25  0]\n",
      "  [ 5  0]]\n",
      "\n",
      " [[ 0 27]\n",
      "  [ 0  3]]\n",
      "\n",
      " [[24  0]\n",
      "  [ 6  0]]]\n",
      "LSTM_Attention_128HUs confusion matrix: \n",
      "[[[25  0]\n",
      "  [ 0  5]]\n",
      "\n",
      " [[26  0]\n",
      "  [ 0  4]]\n",
      "\n",
      " [[23  0]\n",
      "  [ 0  7]]\n",
      "\n",
      " [[25  0]\n",
      "  [ 0  5]]\n",
      "\n",
      " [[27  0]\n",
      "  [ 0  3]]\n",
      "\n",
      " [[24  0]\n",
      "  [ 0  6]]]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confusion_matrices[model_name] = multilabel_confusion_matrix(ytrue, yhat)\n",
    "    print(f\"{model_name} confusion matrix: {os.linesep}{confusion_matrices[model_name]}\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['confusion matrix'] = confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d88643a-3914-4f7d-bb5d-3f4108eb58ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM classification accuracy = 10.0%\n",
      "LSTM_Attention_128HUs classification accuracy = 100.0%\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Model accuracy\n",
    "    classification_accuracies[model_name] = accuracy_score(ytrue, yhat)    \n",
    "    print(f\"{model_name} classification accuracy = {round(classification_accuracies[model_name]*100,3)}%\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['accuracy'] = classification_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6160dfb5-c331-4886-8b50-b76f90461713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM weighted average precision = 0.01\n",
      "LSTM weighted average recall = 0.1\n",
      "LSTM weighted average f1-score = 0.018\n",
      "\n",
      "LSTM_Attention_128HUs weighted average precision = 1.0\n",
      "LSTM_Attention_128HUs weighted average recall = 1.0\n",
      "LSTM_Attention_128HUs weighted average f1-score = 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    yhat = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Get list of classification predictions\n",
    "    ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "    yhat = np.argmax(yhat, axis=1).tolist()\n",
    "    \n",
    "    # Precision, recall, and f1 score\n",
    "    report = classification_report(ytrue, yhat, target_names=actions, output_dict=True)\n",
    "    \n",
    "    precisions[model_name] = report['weighted avg']['precision']\n",
    "    recalls[model_name] = report['weighted avg']['recall']\n",
    "    f1_scores[model_name] = report['weighted avg']['f1-score'] \n",
    "   \n",
    "    print(f\"{model_name} weighted average precision = {round(precisions[model_name],3)}\")\n",
    "    print(f\"{model_name} weighted average recall = {round(recalls[model_name],3)}\")\n",
    "    print(f\"{model_name} weighted average f1-score = {round(f1_scores[model_name],3)}\\n\")\n",
    "\n",
    "# Collect results \n",
    "eval_results['precision'] = precisions\n",
    "eval_results['recall'] = recalls\n",
    "eval_results['f1 score'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ee927a6-0a78-460a-9140-731bde144b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AttnLSTM\n",
    "model_name = 'AttnLSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6518d6b9-d0b4-4cf9-aad7-b35adc406062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    \"\"\"\n",
    "    Computes 3D joint angle inferred by 3 keypoints and their relative positions to one another\n",
    "    \n",
    "    \"\"\"\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f4302c0-1648-4fde-bad2-114dbd806739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_coordinates(landmarks, mp_pose, side, joint):\n",
    "    \"\"\"\n",
    "    Retrieves x and y coordinates of a particular keypoint from the pose estimation model\n",
    "         \n",
    "     Args:\n",
    "         landmarks: processed keypoints from the pose estimation model\n",
    "         mp_pose: Mediapipe pose estimation model\n",
    "         side: 'left' or 'right'. Denotes the side of the body of the landmark of interest.\n",
    "         joint: 'shoulder', 'elbow', 'wrist', 'hip', 'knee', or 'ankle'. Denotes which body joint is associated with the landmark of interest.\n",
    "    \n",
    "    \"\"\"\n",
    "    coord = getattr(mp_pose.PoseLandmark,side.upper()+\"_\"+joint.upper())\n",
    "    x_coord_val = landmarks[coord.value].x\n",
    "    y_coord_val = landmarks[coord.value].y\n",
    "    return [x_coord_val, y_coord_val]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7020ab-fd0e-4b29-9897-851e12793407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_joint_angle(image, angle, joint):\n",
    "    \"\"\"\n",
    "    Displays the joint angle value near the joint within the image frame\n",
    "    \n",
    "    \"\"\"\n",
    "    cv2.putText(image, str(int(angle)), \n",
    "                   tuple(np.multiply(joint, [640, 480]).astype(int)), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd1d3fa8-5ddf-46cd-b778-b3003015619b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_reps(image, current_action, landmarks, mp_pose):\n",
    "    \"\"\"\n",
    "    Counts repetitions of each exercise. Global count and stage (i.e., state) variables are updated within this function.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    global curl_counter, press_counter, squat_counter, pushup_counter, leg_raise_counter, jumping_jacks_counter, curl_stage, press_stage, squat_stage, pushup_stage, leg_raise_stage, jumping_jacks_stage\n",
    "    \n",
    "    if current_action == 'curl':\n",
    "        # Get coords\n",
    "        shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        \n",
    "        # calculate elbow angle\n",
    "        angle = calculate_angle(shoulder, elbow, wrist)\n",
    "        \n",
    "        # curl counter logic\n",
    "        if angle < 30:\n",
    "            curl_stage = \"up\" \n",
    "        if angle > 140 and curl_stage =='up':\n",
    "            curl_stage=\"down\"  \n",
    "            curl_counter +=1\n",
    "        press_stage = None\n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angle\n",
    "        viz_joint_angle(image, angle, elbow)\n",
    "        \n",
    "    elif current_action == 'press':\n",
    "        \n",
    "        # Get coords\n",
    "        shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "\n",
    "        # Calculate elbow angle\n",
    "        elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "        \n",
    "        # Compute distances between joints\n",
    "        shoulder2elbow_dist = abs(math.dist(shoulder,elbow))\n",
    "        shoulder2wrist_dist = abs(math.dist(shoulder,wrist))\n",
    "        \n",
    "        # Press counter logic\n",
    "        if (elbow_angle > 130) and (shoulder2elbow_dist < shoulder2wrist_dist):\n",
    "            press_stage = \"up\"\n",
    "        if (elbow_angle < 50) and (shoulder2elbow_dist > shoulder2wrist_dist) and (press_stage =='up'):\n",
    "            press_stage='down'\n",
    "            press_counter += 1\n",
    "        curl_stage = None\n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angle\n",
    "        viz_joint_angle(image, elbow_angle, elbow)\n",
    "        \n",
    "    elif current_action == 'squat':\n",
    "        # Get coords\n",
    "        # left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "        # right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "        \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        \n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        \n",
    "        # Squat counter logic\n",
    "        thr = 165\n",
    "        if (left_knee_angle < thr) and (right_knee_angle < thr) and (left_hip_angle < thr) and (right_hip_angle < thr):\n",
    "            squat_stage = \"down\"\n",
    "        if (left_knee_angle > thr) and (right_knee_angle > thr) and (left_hip_angle > thr) and (right_hip_angle > thr) and (squat_stage =='down'):\n",
    "            squat_stage='up'\n",
    "            squat_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "            \n",
    "        # Viz joint angles\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "        viz_joint_angle(image, left_hip_angle, left_hip)\n",
    "    \n",
    "    elif current_action == 'pushup':\n",
    "         # Get coordinates\n",
    "         # left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        left_wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "        # right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_elbow = get_coordinates(landmarks, mp_pose, 'right', 'elbow')\n",
    "        right_wrist = get_coordinates(landmarks, mp_pose, 'right', 'wrist')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "    \n",
    "        # Calculate elbow angles\n",
    "        left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "    \n",
    "        # Push-up counter logic\n",
    "        thr_pushup = 170  # Adjust threshold as needed\n",
    "        if (left_elbow_angle < thr_pushup) and (right_elbow_angle < thr_pushup) and (left_hip_angle > 165) and (right_hip_angle > 165):\n",
    "            pushup_stage = \"down\"\n",
    "        if (left_elbow_angle > thr_pushup) and (right_elbow_angle > thr_pushup) and (pushup_stage == 'down') and (left_hip_angle > 165) and (right_hip_angle > 165):\n",
    "            pushup_stage = 'up'\n",
    "            pushup_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        leg_raise_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "        \n",
    "        \n",
    "        # Visualize joint angles\n",
    "        viz_joint_angle(image, left_elbow_angle, left_elbow)\n",
    "        viz_joint_angle(image, right_elbow_angle, right_elbow) \n",
    "        viz_joint_angle(image, left_hip_angle, left_hip)\n",
    "        viz_joint_angle(image, right_hip_angle, right_hip)\n",
    "        \n",
    "    elif current_action == 'leg_raise':\n",
    "         # Get coordinates\n",
    "         # Left side\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "    \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    \n",
    "        # Leg raise counter logic\n",
    "        thr_leg_raise = 160  # Adjust threshold as needed\n",
    "        if left_knee_angle > thr_leg_raise:\n",
    "            leg_raise_stage = \"up\"\n",
    "        if left_knee_angle < thr_leg_raise and leg_raise_stage == 'up':\n",
    "            leg_raise_stage = 'down'\n",
    "            leg_raise_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        jumping_jacks_stage = None\n",
    "        \n",
    "        # Visualize joint angle\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "    \n",
    "    elif current_action == 'jumping_jacks':\n",
    "         # Get coordinates\n",
    "         # Left side\n",
    "        left_shoulder = get_coordinates(landmarks, mp_pose, 'left', 'shoulder')\n",
    "        left_elbow = get_coordinates(landmarks, mp_pose, 'left', 'elbow')\n",
    "        left_wrist = get_coordinates(landmarks, mp_pose, 'left', 'wrist')\n",
    "        left_hip = get_coordinates(landmarks, mp_pose, 'left', 'hip')\n",
    "        left_knee = get_coordinates(landmarks, mp_pose, 'left', 'knee')\n",
    "        left_ankle = get_coordinates(landmarks, mp_pose, 'left', 'ankle')\n",
    "    \n",
    "        # Right side\n",
    "        right_shoulder = get_coordinates(landmarks, mp_pose, 'right', 'shoulder')\n",
    "        right_elbow = get_coordinates(landmarks, mp_pose, 'right', 'elbow')\n",
    "        right_wrist = get_coordinates(landmarks, mp_pose, 'right', 'wrist')\n",
    "        right_hip = get_coordinates(landmarks, mp_pose, 'right', 'hip')\n",
    "        right_knee = get_coordinates(landmarks, mp_pose, 'right', 'knee')\n",
    "        right_ankle = get_coordinates(landmarks, mp_pose, 'right', 'ankle')\n",
    "    \n",
    "        # Calculate elbow angles\n",
    "        left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    \n",
    "        # Calculate knee angles\n",
    "        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    \n",
    "        # Jumping jacks counter logic\n",
    "        thr_jumping_jacks = 160  # Adjust threshold as needed\n",
    "        if (left_elbow_angle < thr_jumping_jacks) and (right_elbow_angle < thr_jumping_jacks) and (left_knee_angle > 165) and (right_knee_angle > 165):\n",
    "            jumping_jacks_stage = \"up\"\n",
    "        if (left_elbow_angle > thr_jumping_jacks) and (right_elbow_angle > thr_jumping_jacks) and (jumping_jacks_stage == 'up'):\n",
    "            jumping_jacks_stage = 'down'\n",
    "            jumping_jacks_counter += 1\n",
    "        curl_stage = None\n",
    "        press_stage = None \n",
    "        squat_stage = None\n",
    "        pushup_stage = None\n",
    "        leg_raise_stage = None\n",
    "        \n",
    "        # Visualize joint angles\n",
    "        viz_joint_angle(image, left_elbow_angle, left_elbow)\n",
    "        viz_joint_angle(image, right_elbow_angle, right_elbow)\n",
    "        viz_joint_angle(image, left_knee_angle, left_knee)\n",
    "        viz_joint_angle(image, right_knee_angle, right_knee)\n",
    "\n",
    "    else:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7475713a-aac6-4d82-ba56-f4e041f7f841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    \"\"\"\n",
    "    This function displays the model prediction probability distribution over the set of exercise classes\n",
    "    as a horizontal bar graph\n",
    "    \n",
    "    \"\"\"\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):        \n",
    "        cv2.rectangle(output_frame, (0,120+num*40), (int(prob*100), 160+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 150+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebee4b05-0cf8-4a60-bab9-2d756024a4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is: C:\\Users\\ACER\\tensor\\project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(f\"The current working directory is: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5440179f-f321-403f-90c7-3223e24d4249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m jumping_jacks_stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Camera object\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Video writer object that saves a video of the real time test\u001b[39;00m\n\u001b[0;32m     28\u001b[0m fourcc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# video compression format\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')\n",
    "# 1. New detection variables\n",
    "sequence = []\n",
    "predictions = []\n",
    "res = []\n",
    "threshold = 0.5 # minimum confidence to classify as an action/exercise\n",
    "current_action = ''\n",
    "\n",
    "# Rep counter logic variables\n",
    "curl_counter = 0\n",
    "press_counter = 0\n",
    "squat_counter = 0\n",
    "pushup_counter = 0\n",
    "leg_raise_counter = 0\n",
    "jumping_jacks_counter = 0\n",
    "curl_stage = None\n",
    "press_stage = None\n",
    "squat_stage = None\n",
    "pushup_stage = None\n",
    "leg_raise_stage = None\n",
    "jumping_jacks_stage = None\n",
    "\n",
    "# Camera object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Video writer object that saves a video of the real time test\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G') # video compression format\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # webcam video frame height\n",
    "WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # webcam video frame width\n",
    "FPS = int(cap.get(cv2.CAP_PROP_FPS)) # webcam video fram rate \n",
    "\n",
    "video_name = os.path.join(os.getcwd(),f\"{model_name}_real_time_test.avi\")\n",
    "out = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*\"MJPG\"), FPS, (WIDTH,HEIGHT))\n",
    "\n",
    "# Set mediapipe model \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detection\n",
    "        image, results = mediapipe_detection(frame, pose)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)        \n",
    "        sequence.append(keypoints)      \n",
    "        sequence = sequence[-sequence_length:]\n",
    "              \n",
    "        if len(sequence) == sequence_length:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]           \n",
    "            predictions.append(np.argmax(res))\n",
    "            current_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "            \n",
    "        #3. Viz logic\n",
    "            # Erase current action variable if no probability is above threshold\n",
    "            if confidence < threshold:\n",
    "                current_action = ''\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "            # Count reps\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                count_reps(\n",
    "                    image, current_action, landmarks, mp_pose)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Display graphical information\n",
    "            #cv2.rectangle(image, (0,0), (640, 80), colors[np.argmax(res)], -1)\n",
    "            cv2.putText(image, 'curl ' + str(curl_counter), (3,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 117, 16), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'press ' + str(press_counter), (240,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (117, 245, 16), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'squat ' + str(squat_counter), (490,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (16, 117, 245), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'pushup ' + str(pushup_counter), (3,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (117, 16, 245), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'leg_raise ' + str(leg_raise_counter), (220,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (245, 16, 117), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, 'jumping_jacks ' + str(jumping_jacks_counter), (490,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (16, 245, 117), 2, cv2.LINE_AA)\n",
    "         \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        # Write to video file\n",
    "        if ret == True:\n",
    "            out.write(image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "785327ce-3016-482e-b33b-aa8a1c0cfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857af89b-e8c0-4c6a-abb3-56456980d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "946125eb-2f5b-4def-8dec-57540047e08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import subprocess\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def set_background_image(window, image_path):\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Convert the image to Tkinter PhotoImage\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    \n",
    "    # Create a label with the image\n",
    "    bg_label = tk.Label(window, image=photo)\n",
    "    bg_label.place(relwidth=1, relheight=1)  # Cover the entire window\n",
    "    \n",
    "    # Keep a reference to the image to avoid garbage collection\n",
    "    bg_label.image = photo\n",
    "\n",
    "# Create a Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"fitness pose estimation\")\n",
    "\n",
    "window_width = 600\n",
    "window_height = 400\n",
    "root.geometry(f\"{window_width}x{window_height}\")\n",
    "\n",
    "min_width = 200\n",
    "min_height = 150\n",
    "root.minsize(min_width, min_height)\n",
    "\n",
    "# Set the maximum window size\n",
    "max_width = 600\n",
    "max_height = 450\n",
    "root.maxsize(max_width, max_height)\n",
    "# Set the background image\n",
    "image_path = r\"C:\\Users\\ACER\\tensor\\project\\image.jpg\"\n",
    "set_background_image(root, image_path)\n",
    "\n",
    "def start_button_clicked():\n",
    "    # Open the next Python file using subprocess\n",
    "    subprocess.run([\"python\", \"C:\\\\Users\\\\ACER\\\\tensor\\\\project\\\\LSTM_Attention_128HUs.py\"])\n",
    "start_button = tk.Button(root, text=\"Start-WorkOut\", command=start_button_clicked,font=('Georgia',13,\"bold\"))\n",
    "start_button.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "\n",
    "# Add other widgets or functionality as needed\n",
    "text_label = tk.Label(root, text=\"Fitness At Home \\nUsing Pose Estimation\",font=('Georgia',25,\"bold\"))\n",
    "text_label.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569de7e-4a3f-4472-ba83-54628475626b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humanpose",
   "language": "python",
   "name": "humanpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
